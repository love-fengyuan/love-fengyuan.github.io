{"meta":{"title":"永远在路上 生命不息 学习不止","subtitle":"请道上大佬，多多指教","description":null,"author":"YuanFeng","url":"http://www.baidu.com","root":"/"},"pages":[{"title":"tags","date":"2019-05-01T21:24:27.000Z","updated":"2019-05-01T15:04:59.023Z","comments":true,"path":"tags/index.html","permalink":"http://www.baidu.com/tags/index.html","excerpt":"","text":""},{"title":"achives","date":"2019-03-10T00:54:40.000Z","updated":"2019-05-01T15:31:29.938Z","comments":true,"path":"achives/index.html","permalink":"http://www.baidu.com/achives/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-05-01T21:24:47.000Z","updated":"2019-05-01T15:06:01.430Z","comments":true,"path":"categories/index.html","permalink":"http://www.baidu.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"django","slug":"django","date":"2019-05-05T20:38:32.000Z","updated":"2019-05-05T12:38:32.852Z","comments":true,"path":"2019/05/06/django/","link":"","permalink":"http://www.baidu.com/2019/05/06/django/","excerpt":"","text":"","categories":[],"tags":[],"author":"yuanfeng"},{"title":"nginx","slug":"nginx","date":"2019-05-05T19:56:58.000Z","updated":"2019-05-05T12:18:50.862Z","comments":true,"path":"2019/05/06/nginx/","link":"","permalink":"http://www.baidu.com/2019/05/06/nginx/","excerpt":"","text":"Nginx服务Nginx现状​nginx 是当前的使用最广泛的webserver ,支持http正向/反向代理，支持TCP/UDP层代理，nginx在全部网站中占比较高，而且一直在增加。当下最时尚的webserver非nginx莫属。 Nginx特点 性能好 非阻塞IO/高并发(asyncio/aiohttp),支持文件IO 多worker，thread pool（线程池- 线程队列） 基于rbtree的定时器 系统特性的持续支持 功能强大 webserver/cache/keepalive/pipeline等等 各种upstream的支持【fastcgi/http/…】 输出灵活【chunk/zip/…】 在不断的发展 http2,tcp,udp,proxy… 运维的友好【这个对于开发和部署很重要】 配置非常规范【个人认为：约定及规范是最好的实践】 热加载和热更新【后文会详细介绍，能在二进制的层面热更新】 日志强大【真的很强的，很多变量支撑】 扩展强大 ​ 下图是nginx、apache和lighttpd的一个对比。系统压力，内存占用，upstream支持等多个方面都非常不错[ nginx对比图](nginx/nginx_compare.png) HTTPS = HTTP + SSL Nginx工作原理​Nginx的运行方式：master-worker多进程模式运行，单线程/非阻塞执行 ​Nginx 启动后生成master，master会启动conf数量的worker进程，当用户的请求过来之后，由不同的worker调起执行线程，非阻塞的执行请求。这种运行方式相对于apache的进程执行相对轻量很多，支撑的并发性也会高很多。 ​Nginx 默认采用守护模式启动，守护模式让master进程启动后在后台运行。在Nginx运行期间主要由一个master主进程和多个worker进程（worker数目一般与cpu数目相同） (1)master主进程 master主进程主要是管理worker进程，对网络事件进行收集和分发： 接收来自外界的信号 向各worker进程发送信号 监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程 (2)worker 工作进程​ nginx用一个独立的worker进程来处理一个请求，一个worker进程可以处理多个请求： ​ a. 当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接。 ​ b. 一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。采用这种方式的好处： 节省锁带来的开销。对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查上时，也会方便很多 独立进程，减少风险。 采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快重新启动新的worker进程。 在一次请求里无需进程切换 (3) Nginx的IO处理过程​一般的Tcp Socket处理过程： ​服务端：fd = socket.socket —&gt; fd.bind() —&gt; fd.listen() —&gt; accept() 等待客户端连接 —&gt; send / recv —&gt; close() 客户端：fd = socket.socket —&gt; fd.connect() 与服务端建立连接 —&gt; recv / send —&gt; close() ​Nginx的网络IO处理通常使用epoll，epoll函数使用了I/O复用模型。与I/O阻塞模型比较，I/O复用模型的优势在于可以同时等待多个（而不只是一个）套接字描述符就绪。Nginx的epoll工作流程如下： master进程先建好需要listen的socket后，然后再fork出多个woker进程，这样每个work进程都可以去accept这个socket 当一个client连接到来时，所有accept的work进程都会受到通知，但只有一个进程可以accept成功，其它的则会accept失败，Nginx提供了一把共享锁accept_mutex来保证同一时刻只有一个work进程在accept连接，从而解决惊群问题。 当一个worker进程accept这个连接后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完成的请求就结束了. Nginx 安装与配置​Nginx服务学习我们借助于一个第三方库Openresty，它本身就是把nginx核心代码做了一层封装，你完全可以把它当成Nginx使用。 ​OpenResty 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。 ​OpenResty 的目标是让你的Web服务直接跑在 Nginx 服务内部，充分利用 Nginx 的非阻塞 I/O 模型，不仅仅对 HTTP 客户端请求,甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及 Redis 等都进行一致的高性能响应。 Openresty下载页： https://openresty.org/cn/download.html 下载版本：wget https://openresty.org/download/openresty-1.11.2.5.tar.gz (Ubuntu 16.x) 最新版本： wget https://openresty.org/download/openresty-1.13.6.2.tar.gz (Ubuntu 17.10) 性能测试工具 Apache AB test 安装过程： （1）安装依赖库： sudo apt install libpcre3 libpcre3-dev sudo apt install openssl libssl-dev （2）安装openresty 123456789#将openresty安装到/opt/openresty目录下sudo mkdir /opt/openresty #修改组和用户权限 apple用户名 : apple组sudo chown -Rf apple:apple /opt/openresty/tar -xzvf openresty-1.11.2.5.tar.gzcd openresty-1.11.2.5 ./configure --prefix=/opt/openresty (注:./configure --help 查看更多的配置选项)makemake install 至此，安装完成，安装openresty就在/opt/openresty目录下。 （3）目录介绍 bin openresty 的启动文件 COPYRIGHT 版权文件 luajit lua虚拟环境luajit lualib lua实现的第三方库，包括redis， mysql， upload， upstream，websocket等等。 nginx nginx核心功能块 pod resty.index site ​openresty不只是提供了nginx功能，而且提供了丰富的工具集，我们可以做除了负载均衡和反向代理之外的很多事情，快速搭建出高性能web服务。 查看进程和端口： ps -ef | grep 80 netstat -tunpl | grep 80 # 修改 vim /opt/openresty/nginx/conf/nginx.conf 中，将listen 80改成 8080 启动nginx服务： $ /opt/openresty/nginx/sbin/nginx 打开页面：http://172.16.245.180:8080/ ​ http://localhost:8080/ 可以看到 Welcome to OpenResty ！ 的页面，表示已经安装成功！ 如果之前已安装了nginx 删除或停止它的服务： ​sudo apt remove nginx 或 ​sudo servie nginx stop 5 OpenResty 使用配置文件Openresty 框架的配置和nginx配置方法一样，配置文件: /opt/openresty/nginx/conf/nginx.conf ​Nginx主要通过nginx.conf文件进行配置使用。在nginx.conf文件中主要分为： 全局块：一些全局的属性，在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等 event块：参考事件模型，单个进程最大连接数等 http块：设定http服务器 server块：配置虚拟主机 location块：配置请求路由及页面的处理情况等 关键参数说明： nginx进程数，建议设置为等于CPU总核心数。 worker_processes 8; 全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] error_log /usr/local/nginx/logs/error.log info; 进程pid文件 pid /opt/openresty/nginx/logs/nginx.pid; 指定进程可以打开的最大描述符：数目 工作模式与连接数上限 这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 worker_rlimit_nofile 65535; 虚拟主机的配置12345678910111213141516171819202122232425server&#123; #监听端口 listen 80; #域名可以有多个，用空格隔开, cat /etc/hosts server_name www.jd.com jd.com; index index.html index.htm index.php; root /data/www/jd; #url 请求路由 location /hello &#123; default_type text/html; content_by_lua &apos; ngx.say(&quot;&lt;p&gt;Hello, World!&lt;/p&gt;&quot;) &apos;; &#125;&#125;#负载均衡配置upstream piao.jd.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weight参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3;&#125; 启动测试拷贝我们的工程文件 artproject.zip，解压到某一个目录 eg: /home/apple根目录下 配置nginx配置文件nginx.conf，添加如下信息： 1234567891011121314location /hello&#123; default_type text/html; content_by_lua &apos; ngx.say(&quot;&lt;p&gt;Hello, World!&lt;/p&gt;&quot;)&apos;;&#125;# 静态文件，nginx自己处理location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root /home/apple/artproject/art; # 过期1天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 1d;&#125; $ /opt/openresty/nginx/sbin/nginx -s stop, quit, reopen, reload $ /opt/openresty/nginx/sbin/nginx -t 测试 nginx: the configuration file /opt/openresty/nginx/conf/nginx.conf syntax is ok nginx: configuration file /opt/openresty/nginx/conf/nginx.conf test is successful 查看页面效果 http://172.16.245.180:8080/hello http://172.16.245.180:8080/static/admin/pages/index.html 负载均衡策略​负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。 ​Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略 RR （轮询策略）​按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。 权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 1234upstream test&#123; server localhost:8080 weight=9; server localhost:8081 weight=1;&#125; 此时8080和8081分别占90%和10%。 ip_hash上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream test &#123; ip_hash; server localhost:8080; server localhost:8081;&#125; fair(第三方) 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream backend &#123; fair; server localhost:8080; server localhost:8081;&#125; url_hash(第三方) 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。 123456upstream backend &#123; hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081;&#125; 处理动态请求转发到某一个服务12345​ location = / &#123; ​ proxy_pass http://localhost:8080 ​ &#125; ​此处的proxy_pass 对应的服务，会导到上述upstream入口 作为静态资源服务器​Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作（CDN），这就是网站静态化处理的核心思路。 123456# 静态文件，nginx自己处理location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root /home/apple/artproject/art; # 过期1天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 1d;&#125; 关于URL路由规则语法规则：1234567location [=|~|~*|^~] /uri/ &#123; ​ … &#125; = 开头表示精确匹配 ^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。 ~ 开头表示区分大小写的正则匹配 ~* 开头表示不区分大小写的正则匹配 !~和!~*分别为区分大小写不匹配及不区分大小写不匹配 的正则 / 通用匹配，任何请求都会匹配到。 多个location配置的情况下匹配顺序为： 首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。 例子，有如下匹配规则： 123456789101112131415161718192021222324location = / &#123; #规则A&#125;location = /login &#123; #规则B&#125;location ^~ /static/ &#123; #规则C&#125;location ~ \\.(gif|jpg|png|js|css)$ &#123; #规则D&#125;location ~* \\.png$ &#123; #规则E&#125;location !~ \\.xhtml$ &#123; #规则F&#125;location !~* \\.xhtml$ &#123; #规则G&#125;location / &#123; #规则H&#125; 那么产生的效果如下: 访问根目录/， 比如http://localhost/ 将匹配规则A访问 http://localhost/login 将匹配规则B，http://localhost/register 则匹配规则H访问 http://localhost/static/a.html 将匹配规则C访问 http://localhost/a.gif, http://localhost/b.jpg 将匹配规则D和规则E，但是规则D顺序优先，规则E不起作用，而 http://localhost/static/c.png 则优先匹配到规则C访问 http://localhost/a.PNG 则匹配规则E，而不会匹配规则D，因为规则E不区分大小写。 访问 http://localhost/a.xhtml 不会匹配规则F和规则G，http://localhost/a.XHTML不会匹配规则G，因为不区分大小写。规则F，规则G属于排除法，符合匹配规则但是不会匹配到，所以想想看实际应用中哪里会用到。 访问 http://localhost/category/id/1111 则最终匹配到规则H，因为以上规则都不匹配，这个时候应该是nginx转发请求给后端应用服务器，比如FastCGI（php），tomcat（jsp），nginx作为方向代理服务器存在。","categories":[{"name":"nginx","slug":"nginx","permalink":"http://www.baidu.com/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://www.baidu.com/tags/nginx/"}],"author":"yuanfeng"},{"title":"python设计模式","slug":"python_design_pattern","date":"2019-05-05T19:27:52.000Z","updated":"2019-05-05T11:31:54.825Z","comments":true,"path":"2019/05/06/python_design_pattern/","link":"","permalink":"http://www.baidu.com/2019/05/06/python_design_pattern/","excerpt":"","text":"七大设计原则七大设计原则： 1、单一职责原则【SINGLE RESPONSIBILITY PRINCIPLE】：一个类负责一项职责. 2、里氏替换原则【LISKOV SUBSTITUTION PRINCIPLE】：继承与派生的规则.（子类可替换父类） 3、依赖倒转原则【DEPENDENCE INVERSION PRINCIPLE】：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。即针对接口编程，不要针对实现编程。 4、接口隔离原则【INTERFACE SEGREGATION PRINCIPLE】：建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。 5、迪米特法则【LOW OF DEMETER】：高内聚 低耦合 – high cohesion low coupling 6、开闭原则【OPEN CLOSE PRINCIPLE】：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 7、组合/聚合复用原则【Composition/Aggregation Reuse Principle(CARP) 】：尽量使用组合和聚合少使用继承的关系来达到复用的原则。 二十四种模式创建型模式 1、抽象工厂模式(Abstract factory pattern): 提供一个接口, 用于创建相关或依赖对象的家族, 而不需要指定具体类. 2、生成器模式(Builder pattern): 使用生成器模式封装一个产品的构造过程, 并允许按步骤构造. 将一个复杂对象的构建与它的表示分离, 使得同样的构建过程可以创建不同的表示. 3、工厂模式(factory method pattern): 定义了一个创建对象的接口, 但由子类决定要实例化的类是哪一个. 工厂方法让类把实例化推迟到子类. 4、原型模式(prototype pattern): 当创建给定类的实例过程很昂贵或很复杂时, 就使用原形模式. 5、单例了模式(Singleton pattern): 确保一个类只有一个实例, 并提供全局访问点. 6、多例模式(Multition pattern): 在一个解决方案中结合两个或多个模式, 以解决一般或重复发生的问题. 结构型模式 1、适配器模式(Adapter pattern): 将一个类的接口, 转换成客户期望的另一个接口. 适配器让原本接口不兼容的类可以合作无间. 对象适配器使用组合, 类适配器使用多重继承. 2、桥接模式(Bridge pattern): 使用桥接模式通过将实现和抽象放在两个不同的类层次中而使它们可以独立改变. 3、组合模式(composite pattern): 允许你将对象组合成树形结构来表现”整体/部分”层次结构. 组合能让客户以一致的方式处理个别对象以及对象组合. 4、装饰者模式(decorator pattern): 动态地将责任附加到对象上, 若要扩展功能, 装饰者提供了比继承更有弹性的替代方案. 5、外观模式(facade pattern): 提供了一个统一的接口, 用来访问子系统中的一群接口. 外观定义了一个高层接口, 让子系统更容易使用. 6、亨元模式(Flyweight Pattern): 如想让某个类的一个实例能用来提供许多”虚拟实例”, 就使用蝇量模式. 7、代理模式(Proxy pattern): 为另一个对象提供一个替身或占位符以控制对这个对象的访问. 行为型模式 1、责任链模式(Chain of responsibility pattern): 通过责任链模式, 你可以为某个请求创建一个对象链. 每个对象依序检查此请求并对其进行处理或者将它传给链中的下一个对象. 2、命令模式(Command pattern): 将”请求”封闭成对象, 以便使用不同的请求,队列或者日志来参数化其他对象. 命令模式也支持可撤销的操作. 3、解释器模式(Interpreter pattern): 使用解释器模式为语言创建解释器. 4、迭代器模式(iterator pattern): 提供一种方法顺序访问一个聚合对象中的各个元素, 而又不暴露其内部的表示. 5、中介者模式(Mediator pattern) : 使用中介者模式来集中相关对象之间复杂的沟通和控制方式. 6、备忘录模式(Memento pattern): 当你需要让对象返回之前的状态时(例如, 你的用户请求”撤销”), 你使用备忘录模式. 7、观察者模式(observer pattern): 在对象之间定义一对多的依赖, 这样一来, 当一个对象改变状态, 依赖它的对象都会收到通知, 并自动更新. 8、状态模式(State pattern): 允许对象在内部状态改变时改变它的行为, 对象看起来好象改了它的类. 9、策略模式(strategy pattern): 定义了算法族, 分别封闭起来, 让它们之间可以互相替换, 此模式让算法的变化独立于使用算法的客户. 10、模板方法模式(Template pattern): 在一个方法中定义一个算法的骨架, 而将一些步骤延迟到子类中. 模板方法使得子类可以在不改变算法结构的情况下, 重新定义算法中的某些步骤. 11、访问者模式(visitor pattern): 当你想要为一个对象的组合增加新的能力, 且封装并不重要时, 就使用访问者模式. 参考https://blog.csdn.net/weixin_41781973/article/details/80630337 https://www.cnblogs.com/beijiguangyong/archive/2010/11/15/2302807.html#4130080 https://www.cnblogs.com/Liqiongyu/p/5916710.html https://github.com/w392807287/Design_pattern_of_python","categories":[],"tags":[],"author":"yuanfeng"},{"title":"LVS","slug":"LVS","date":"2019-04-18T15:22:43.000Z","updated":"2019-05-05T07:30:06.599Z","comments":true,"path":"2019/04/18/LVS/","link":"","permalink":"http://www.baidu.com/2019/04/18/LVS/","excerpt":"","text":"LVSLVS(linux virtual server)即linux虚拟服务器，是一个虚拟的服务器集群系统。 使用集群技术和Linux操作系统实现一个高性能,高可用的服务器,很好的可伸缩性(scalability),很好的可靠性(reliability),很好的可管理性(manageability). contos7: grep -i ipvs /boot/config-3.10.0-693.e17.x86_64 grep -i ipvs -C 10 /boot/config-3.10.0-693.e17.x86_64 yum install ipvsadm rpm -ql ipvsadm curl命令 lvs服务器:需要两块网卡 启用Ipforward： echo net.ipv4.ip_forward=1 &gt;&gt; /etc/sysctl.conf sysctl -p sysctl -a | grep ip_forward iptables -vnl client：需要桥接 RS1：设置网关 yum install httpd echo RS1 &gt; /var/www/html/index.html RS2；设置网关 yum install httpd echo RS2 &gt; /var/www/html/index.html LVS： 定义ipvs规则:NAt模式 yum install ipvsadm ipvsadm -A -t 172.20.0.200:80 -s rr ipvsadm -Ln ipvsadm -a -t 172.20.0.200:80 -r 192.168.80.17 -m ipvsadm -a -t 172.20.0.200:80 -r 192.168.80.27 -m ipvsadm -Ln 并发4百万 apache 1万 集群Cluster概念 系统扩展方式： scale up: 向上扩展，增强 scale out: 向外扩展，增加设备，调度分配问题， cluster Cluster: 集群，未解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster类型： LB：load blancing, 负载均衡 HA：high availiablity, 高可用， spof(single point of failure) MTBF: Mean Time Between Failure 平均无故障时间 MTTR: Mean Time To REStoration (repair) 平均恢复前时间（故障时间） A=MTBF/(MTBF+MTTR) (0,1): 99%,99.5%, 99.9%, 99.99%, 99.999% HPC: high-performance computing . 高性能 www.top500.org 分布式系统：分布式存储： 云盘 分布式计算： hadoop, spark Cluster分类 LB Cluster的实现 硬件：F5 big-ip citrix netscaler A10 A10 软件:lvs: linux virtual server nginx: 支持七层调度 haproxy: 支持七层调度 ats: apache trafficserver perlbal: perl编写 pound 基于工作的协议层划分： 传输层（通用）：DPORT LVS： nginx：stream haproxy: mode tcp 应用层（专用）：针对特定协议，自定义的请求模型分类 proxy server： http:nginx, httpdm haproxy(mode http),... fastcgi: nginx, httpd, ... mysql: mysql-proxy,... 会话保持：负载均衡 （1）session sticky: 同一用户调度固定服务器 source ip: lvs sh算法（对某一特定服务而言） cookie （2）session replication: 每台服务器拥有全部session session multicast cluster （3）session server: 专门的session服务器 memcached， redis HA集群实现方案 keepalived: vrrp协议 ais：应用接口规范heartbeat cman + rgmanager(RHCS) coresync_pacemaker LVS介绍LVS介绍 LVS: linux virtual server, 负载调度器，集成内核 官网：http://www.linuxvirtualserver.org/ VS：virtual server，负责调度 RS：real server,负责真正提供服务 L4：四层路由器或交换机 工作原理：vs根据请求报文的目标ip和目标协议及端口将其调度转发至某RS，根据调度算法来挑选RS iptables/netfilter: iptables:用户空间的管理工具 netfilter:内核空间上的框架 流入：PREROUTING–&gt;INPUT 流出：OUTPUT–&gt; POSTROUTING 转发：PREROUTING–&gt;FORWARD–&gt;POSTROUTING DNAT：目标地址转换；PREROUTING LVS概念 lvs集群类型中的术语： VS：virtual server, director server(DS) dispatcher(调度器)，load balancer RS:real server(lvs), upstream server(nginx) backend server(haproxy) CIP:client ip VIP:virtual serve ip VS外网的ip DIP:director ip VS内网Ip RIP:real server ip 访问流程：CIPVIP==DIPRIP LVS集群的类型 lvs: ipvsadm/ipvs ipvsadm: 用户空间的命令行工具，规则管理器 ipvs: 工作于内核空间netfilter的INPUT钩子上的框架 lvs集群的类型： lvs-nat: 修改请求报文的目标IP，多目标IP的DNAT lvs-dr: 操纵封装新的MAC地址 lvs-tun: 在原请求IP报文之外新加一个IP首部 lvs-fullnat: 修改请求报文的源和目标IP lvs-nat模式 lvs-nat: 本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发 (1)RIP和DIP应在同一个IP网络，且应使用私网地址，RS的网关要指向DIP (2)请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈 (3)支持端口映射，可修改请求报文的目标PORT (4)VS必须是linux系统，RS可以是任意OS系统 lvs-fullnat模式 lvs-fullnat: 通过同时修改请求报文的源IP地址和目标IP地址进行转发CIP--&gt;DIP VIP--&gt;RIP (1)VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此。RIP的网关一般不会指向DIP (2)RS收到的请求报文源地址是DIP，因此，只需响应给DIP；但Director还要将其发往Client (3)请求和响应报文都经由Director (4)支持端口映射 注意：此类型kernel默认不支持 LVS工作模式总结 VS/NAT VS/TUN VS/DR server any tunneling non-arp device server network private LAN/WAN LAN server number low(10~20) high(100) high(100) server gateway load balancer own router own router lvs-nat与lvs-fullnat:请求和响应报文都经由director lvs-nat:RIP的网关要指向DIP lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信 lvs-dr与lvs-tun:请求报文要经由director，但相应报文有RS直接发往client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发 lvs-tun: 通过在院IP报文外封装新IP头实现转发，支持远距离通信 ipvs scheduler ipvs scheduler: 根据其调度时是否考虑各RS当前的负载状态 两种：静态方法和动态方法 静态方法：仅根据算法本身进行调度 1. RR: roundrobin,轮询 2. WRR: weighted RR,加权轮询 3. SH: source hashing,实现session sticky，源IP地址hash；将来自同一个IP地址的请求，始终发往第一次挑中的RS，从而实现会话绑定 4. DH: destination hashing, 目标地址哈希，将发往同一个目标地址的骑牛始终发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡；如：宽带运行商 动态方法： 主要根据每个RS当前的负载状态及调度算法进行调度overhead=value较小的RS将被调度 LC: least connections 适用于长连接应用 overhead=activeconns*256+inactiveconns WLC: weighted LC,默认调度方法 overhead=(acticeconns*256+inactiveconns)/weight SED: shortest expection delay,初始连接高权重优先 overhead=(activeconns+1)*256/weight NQ: never queue, 第一轮均匀分配，后续sed LBLC: locality-based LC，动态的DH算法，使用场景：根据负载状态实现正向代理 LBLCR: LBLC with replication, 带复制功能的LBLC，解决LBLC负载不均衡问题，从负载重的复制到负载轻的RS ipvsadm命令 ipvsadm 命令： 核心功能： 集群服务管理：增，删，改 集群服务的RS管理：增，删，改 查看 ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [–pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address 删除 ipvsadm -C 清空 ipvsadm -R 重载 ipvsadm -S [-n] 保存 ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|U|f service-address] 管理集群上的RS：增，删，改 增、改：ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 删：ipvsadm -d -t|u|f service-address -r server-address server-addres: rip[:port] 如省略port，不作端口映射 选项： lvs类型:-g: gateway, dr类型，默认 -i: ipip，tun类型 -m: masquerade, nat类型 -w weight: 权重 参考http://blog.sina.com.cn/s/blog_6786545e0102vjvq.html","categories":[{"name":"lvs","slug":"lvs","permalink":"http://www.baidu.com/categories/lvs/"}],"tags":[{"name":"lvs","slug":"lvs","permalink":"http://www.baidu.com/tags/lvs/"}],"author":"yuanfeng"},{"title":"django集成celery","slug":"django_celery","date":"2019-04-17T19:22:43.000Z","updated":"2019-05-05T12:39:42.276Z","comments":true,"path":"2019/04/18/django_celery/","link":"","permalink":"http://www.baidu.com/2019/04/18/django_celery/","excerpt":"","text":"Django集成Celery到项目将celery集成到Django项目中，实现异步任务处理和定时任务处理 Celery工作流程 celery流程图 Celery的架构由三部分组成，消息中间件（message broker），任务执行单元（worker）和任务执行结果存储（task result store）组成。 消息中间件 Celery本身不提供消息服务，但是可以方便的和第三方提供的消息中间件集成。包括，RabbitMQ, Redis, MongoDB (experimental), Amazon SQS (experimental),CouchDB (experimental), SQLAlchemy (experimental),Django ORM (experimental), IronMQ 任务执行单元 Worker是Celery提供的任务执行的单元，worker并发的运行在分布式的系统节点中。 任务结果存储 Task result store用来存储Worker执行的任务的结果，Celery支持以不同方式存储任务的结果，包括AMQP, Redis，memcached, MongoDB，SQLAlchemy, Django ORM，Apache Cassandra, IronCache 1.Celery安装与配置在虚拟环境中安装: pip install django-celery==3.2.2 pip install django-redis pip install flower # celery 的web管理平台(异步任务可视化) 查看集成到Django中的celery版本， pip freeze celery==3.1.26.post2 django-celery==3.2.2 flower==0.9.2 启动redis服务， 端口假设为6379 发现pip安装比较慢的情况 pip install pillow -i https://pypi.douban.com/simple 2.Django中配置（1）在主工程的配置文件settings.py 中应用注册表INSTALLED_APPS中加入 djcelery12345678910111213INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;art&apos;, &apos;xadmin&apos;, &apos;crispy_forms&apos;, &apos;DjangoUeditor&apos;, &apos;djcelery&apos;, #加入djcelery] (2) 在settings.py 中加入celery配置信息12345678910111213141516171819202122# celery 配置信息 startimport djcelerydjcelery.setup_loader()BROKER_URL = &apos;redis://127.0.0.1:6379/1&apos;CELERY_IMPORTS = (&apos;art.tasks&apos;)CELERY_TIMEZONE = &apos;Asia/Shanghai&apos;CELERYBEAT_SCHEDULER = &apos;djcelery.schedulers.DatabaseScheduler&apos; from celery.schedules import crontabfrom celery.schedules import timedeltaCELERYBEAT_SCHEDULE = &#123; #定时器策略 #定时任务一： 每隔30s运行一次 u&apos;测试定时器1&apos;: &#123; &quot;task&quot;: &quot;art.tasks.tsend_email&quot;, #&quot;schedule&quot;: crontab(minute=&apos;*/2&apos;), # or &apos;schedule&apos;: timedelta(seconds=3), &quot;schedule&quot;:timedelta(seconds=30), &quot;args&quot;: (), &#125;,&#125;# celery 配置信息 end ​ 当djcelery.setup_loader()运行时，Celery便会去查看INSTALLD_APPS下包含的所有app目录中的tasks.py文件，找到标记为task的方法，将它们注册为celery task ​ BROKER_URL：broker是代理人，它负责分发任务给worker去执行。我使用的是Redis作为broker ​ 没有设置 CELERY_RESULT_BACKEND，默认没有配置，此时Django会使用默认的数据库(也是你指定的orm数据库)。 CELERY_IMPORTS：是导入目标任务文件 CELERYBEAT_SCHEDULER：使用了django-celery默认的数据库调度模型,任务执行周期都被存在默认指定的orm数据库中． CELERYBEAT_SCHEDULE：设置定时的时间配置， 可以精确到秒，分钟，小时，天，周等。 （3）创建应用实例​在主工程目录添加celery.py， 添加自动检索django工程tasks任务 ​vim artproject/celery.py 1234567891011121314151617#!/usr/bin/env python # encoding: utf-8 #目的是拒绝隐士引入，celery.py和celery冲突。from __future__ import absolute_import,unicode_literals import osfrom celery import Celeryfrom django.conf import settings# 设置环境变量os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;artproject.settings&quot;)#创建celery应用app = Celery(&apos;art_project&apos;)app.config_from_object(&apos;django.conf:settings&apos;)#如果在工程的应用中创建了tasks.py模块，那么Celery应用就会自动去检索创建的任务。比如你添加了一个任#务，在django中会实时地检索出来。app.autodiscover_tasks(lambda :settings.INSTALLED_APPS) (4) 创建任务 tasks每个任务本质上就是一个函数，在tasks.py中，写入你想要执行的函数即可。 在应用art中添加我们需要提供的异步服务和定时服务 vim art/tasks.py 1234567891011121314151617181920212223#!/usr/bin/env python # encoding: utf-8 from __future__ import absolute_importimport timefrom django.core.mail import send_mailfrom celery.utils.log import get_task_loggerfrom artproject.celery import appfrom art.utils.send_mail import pack_html, send_email@app.taskdef tsend_email(): url = &quot;http://1000phone.com&quot; receiver = &apos;diyuhuan@1000phone.com&apos; content = pack_html(receiver, url) # content = &apos;this is email content.&apos; send_email(receiver, content) print(&apos;send email ok!&apos;)@app.taskdef add(x, y): return x+y 上述我们把异步处理任务add和定时器任务tsend_email都放在了tasks.py 中 （5）迁移生成celery需要的数据表python manage.py migrate 此时数据库表结构多出了几个 12345678celery_taskmeta || celery_tasksetmeta || djcelery_crontabschedule || djcelery_intervalschedule || djcelery_periodictask || djcelery_periodictasks || djcelery_taskstate || djcelery_workerstate 3.启动服务，测试我们可以采用 python manage.py help 发现多出了 celery 相关选项。 （1）启动django celery 服务启动服务： python manage.py celery worker --loglevel=info 此时异步处理和定时处理服务都已经启动了 （2）web端接口触发异步任务处理我们在web端加入一个入口，触发异步任务处理add函数 在应用art的urls.py 中加入如下对应关系 123from art.views import add_handlerurl(r&apos;^add&apos;, add_handler), art/views.py 中加入处理逻辑 1234567def add_handler(request): x = request.GET.get(&apos;x&apos;, &apos;1&apos;) y = request.GET.get(&apos;y&apos;, &apos;1&apos;) from .tasks import add add.delay(int(x), int(y)) res = &#123;&apos;code&apos;:200, &apos;message&apos;:&apos;ok&apos;, &apos;data&apos;:[&#123;&apos;x&apos;:x, &apos;y&apos;:y&#125;]&#125; return HttpResponse(json.dumps(res)) 启动web服务，通过url传入的参数，通过handler的add.delay(x, y)计算并存入mysql http://127.0.0.1:8000/art/add?x=188&amp;y=22 (4)测试定时器，发送邮件在终端输入 python manage.py celerybeat -l info 会自动触发每隔30s执行一次tsend_email定时器函数，发送邮件： 123456789CELERYBEAT_SCHEDULE = &#123; #定时器策略 #定时任务一： 每隔30s运行一次 u&apos;测试定时器1&apos;: &#123; &quot;task&quot;: &quot;art.tasks.tsend_email&quot;, #&quot;schedule&quot;: crontab(minute=&apos;*/2&apos;), # or &apos;schedule&apos;: timedelta(seconds=3), &quot;schedule&quot;:timedelta(seconds=30), &quot;args&quot;: (), &#125;,&#125; 具体发送邮件服务程序见下面的第4节 4.邮件发送服务项目中经常会有定时发送邮件的情形，比如发送数据报告，发送异常服务报告等。 可以编辑文件 art/utils/send_mail.py, 内容编辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/usr/bin/env python#-*- coding:utf-8 -*-#written by diyuhuan#发送邮件(wd_email_check123账号用于内部测试使用，不要用于其他用途)import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.image import MIMEImage from email.header import Headerimport timesender = &apos;wd_email_check123@163.com&apos; subject = u&apos;api开放平台邮箱验证&apos;smtpserver = &apos;smtp.163.com&apos;username = &apos;wd_email_check123&apos;password = &apos;wandacheck1234&apos;mail_postfix=&quot;163.com&quot;def send_email(receiver, content): try: me = username+&quot;&lt;&quot;+username+&quot;@&quot;+mail_postfix+&quot;&gt;&quot; msg = MIMEText(content, &apos;html&apos;, &apos;utf-8&apos;) msg[&apos;Subject&apos;] = subject msg[&apos;From&apos;] = sender msg[&apos;To&apos;] = receiver smtp = smtplib.SMTP() smtp.connect(smtpserver) smtp.login(username, password) smtp.sendmail(sender, receiver, msg.as_string()) smtp.quit() return True except Exception as e: print(&apos;send_email has error with : &apos; + str(e)) return Falsedef pack_html(receiver, url): html_content = u&quot;&lt;html&gt;&lt;div&gt;尊敬的用户&lt;font color=&apos;#0066FF&apos;&gt;%s&lt;/font&gt; 您好！&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;感谢您关注我们的平台 ，我们将为您提供最贴心的服务，祝您购物愉快。&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;点击以下链接，即可完成邮箱安全验证：&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;&lt;a href=&apos;%s&apos;&gt;%s&lt;/a&gt;&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;为保障您的帐号安全，请在24小时内点击该链接; &lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;若您没有申请过验证邮箱 ，请您忽略此邮件，由此给您带来的不便请谅解。&lt;/div&gt;&quot; \\ &quot;&lt;/html&gt;&quot; % (receiver, url, url) html_content = html_content return html_contentif __name__ == &quot;__main__&quot;: url = &quot;http://1000phone.com&quot; receiver = &apos;diyuhuan@1000phone.com&apos; #content = pack_html(receiver, url) content = &apos;this is email content. at %s.&apos;%int(time.time()) send_email(receiver, content) 至此，在celery ui界面可以看到两类，定时器处理和异步处理。 5.启动flower服务python manager celery flower","categories":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/tags/django/"},{"name":"celery","slug":"celery","permalink":"http://www.baidu.com/tags/celery/"}],"author":"yuanfeng"},{"title":"django中的日志处理","slug":"django_logging","date":"2019-04-17T19:22:43.000Z","updated":"2019-05-05T11:56:10.006Z","comments":true,"path":"2019/04/18/django_logging/","link":"","permalink":"http://www.baidu.com/2019/04/18/django_logging/","excerpt":"","text":"1 Django中加入日志功能Django 中使用python的 logging 模块记录log，在 Django 中使用 Django 提供的配制方法。就是在 settings 中通过变量 LOGGING，LOGGING 是一个字典，典型的配置如下： ​logging模块为应用程序提供了灵活的手段记录事件、错误、警告和调试信息。对这些信息可以进行收集、筛选、写入文件、发送给系统日志等操作，甚至还可以通过网络发送给远程计算机。 （1）日志记录级别​logging模块的重点在于生成和处理日志消息。每条消息由一些文本和指示其严重性的相关级别组成。级别包含符号名称和数字值。 级别 值 描述 CRITICAL/FATAL 50 关键错误/消息 ERROR 40 错误 WARNING 30 警告消息 INFO 20 通知消息 DEBUG 10 调试 NOTSET 0 无级别 （2）记录器（日志对象-logging.getLogger()）-默认的root记录器​记录器负责管理日志消息的默认行为，包括日志记录级别、输出目标位置、消息格式以及其它基本细节。 如下是处理器Handler关键的参数： 关键字参数 描述 filename 将日志消息附加到指定文件名的文件 filemode 指定用于打开文件模式 format 用于生成日志消息的格式字符串 datefmt 用于输出日期和时间的格式字符串 level 设置记录器的级别 stream 提供打开的文件，用于把日志消息发送到文件。 （3）format 日志消息格式​e.g. ‘%(asctime)s %(module)s %(level)s %(lineno)d’ 格式 描述 %(name)s 记录器的名称, 默认为root %(levelno)s 数字形式的日志记录级别 %(levelname)s 日志记录级别的文本名称 %(filename)s 执行日志记录调用的源文件的文件名称 %(pathname)s 执行日志记录调用的源文件的路径名称 %(funcName)s 执行日志记录调用的函数名称 %(module)s 执行日志记录调用的模块名称 %(lineno)s 执行日志记录调用的行号 %(created)s 执行日志记录的时间 %(asctime)s 日期和时间 %(msecs)s 毫秒部分 %(thread)d 线程ID %(threadName)s 线程名称 %(process)d 进程ID %(message)s 记录的消息 （4）内置处理器​ logging模块提供了一些处理器，可以通过各种方式处理日志消息。使用addHandler()方法将这些处理器添加给Logger对象。另外还可以为每个处理器配置它自己的筛选和级别。 ​ handlers.DatagramHandler(host，port):发送日志消息给位于制定host和port上的UDP服务器。 ​ * handlers.FileHandler(filename): 将日志消息写入文件filename。 ​ handlers.HTTPHandler(host, url):使用HTTP的GET或POST方法将日志消息上传到一台HTTP 服务器。 ​ * handlers.RotatingFileHandler(filename):将日志消息写入文件filename。如果文件的大小超出maxBytes制定的值，那么它将被备份为filename1。 ​ 由于内置处理器还有很多，如果想更深入了解。可以查看官方手册。 （5）python的日志简单地用法1234567891011# 设置日志等级logging.getLogger().setLevel(logging.INFO)formatter = '%(asctime)s: %(filename)s/%(funcName)s at %(lineno)s-&gt;%(message)s'# 配置日志的信息，filename 要指定日志输出的文件名logging.basicConfig(format=formatter, datefmt='%Y-%m-%d %H:%M:%S', filename='art.log', filemode='a')logging.warning('--当前页面要被缓存5秒---') 2 Django中使用日志在Django的配置文件settings.py 中加入如下LOGGING配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566## Django Logging BEGIN#LOGGING_DIR 日志文件存放目录LOGGING_DIR = &quot;/home/xxt/logs&quot;if not os.path.exists(LOGGING_DIR): os.mkdir(LOGGING_DIR)import loggingLOGGING = &#123; &apos;version&apos;: 1, &apos;disable_existing_loggers&apos;: False, &apos;formatters&apos;: &#123; &apos;standard&apos;: &#123; &apos;format&apos;: &apos;[%(levelname)s][%(asctime)s][%(filename)s][%(funcName)s][%(lineno)d] &gt; %(message)s&apos; &#125;, &apos;simple&apos;: &#123; &apos;format&apos;: &apos;[%(levelname)s]&gt; %(message)s&apos;, &apos;datefmt&apos;: &apos;%Y-%m-%d %H:%M:%S&apos; &#125;, &#125;, &apos;filters&apos;: &#123; &apos;require_debug_true&apos;: &#123; &apos;()&apos;: &apos;django.utils.log.RequireDebugTrue&apos;, &#125;, &#125;, &apos;handlers&apos;: &#123; &apos;console&apos;: &#123; &apos;level&apos;: &apos;DEBUG&apos;, &apos;filters&apos;: [&apos;require_debug_true&apos;], &apos;class&apos;: &apos;logging.StreamHandler&apos;, &apos;formatter&apos;: &apos;simple&apos; &#125;, &apos;file_handler&apos;: &#123; &apos;level&apos;: &apos;INFO&apos;, &apos;class&apos;: &apos;logging.handlers.TimedRotatingFileHandler&apos;, &apos;filename&apos;: &apos;%s/django.log&apos; % LOGGING_DIR, &apos;formatter&apos;:&apos;standard&apos;, &apos;encoding&apos;: &apos;utf-8&apos; &#125;, # 用于文件输出 &apos;mail_admins&apos;: &#123; &apos;level&apos;: &apos;ERROR&apos;, &apos;class&apos;: &apos;django.utils.log.AdminEmailHandler&apos;, &apos;formatter&apos;:&apos;standard&apos; &#125;, &#125;, &apos;loggers&apos;: &#123; &apos;mdjango&apos;: &#123; &apos;handlers&apos;: [&apos;console&apos;,&apos;file_handler&apos;], &apos;level&apos;:&apos;DEBUG&apos;, &apos;propagate&apos;: True, &#125;, &apos;django.request&apos;: &#123; &apos;handlers&apos;: [&apos;mail_admins&apos;], &apos;level&apos;: &apos;ERROR&apos;, &apos;propagate&apos;: False, &#125;, &#125;&#125; logger = logging.getLogger(&quot;mdjango&quot;)## Django Logging END 最新日志内容存入： django.log 前一天：django.log.2018-05-29 前前一天：django.log.2018-05-28 django.log.2018-05-22 在具体的业务逻辑代码中加入日志记录 123from Project.settings import loggerlogger.info(&quot;IndexHandler request Handler begin&quot;)logger.debug(&apos;query total:&apos; + str(total)) 观察日志打印情况。 一般python使用日志功能（非django框架） 12345678910111213import loggingdef logging_init(): app_name = &quot;AppName&quot; log_file_name = &quot;myapp_test.log&quot; logger = logging.getLogger(app_name) format_str = &quot;[%(asctime)s][%(levelname)s]&gt; %(message)s&quot; formatter = logging.Formatter(format_str) file_handler = logging.FileHandler(log_file_name) file_handler.setFormatter(formatter) logger.addHandler(file_handler) logger.setLevel(logging.INFO) return logger 单例模式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import loggingclass Singleton(object): _instance = None def __new__(cls, *args, **kwargs): if not cls._instance: cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls._instance app_name = &quot;appName&quot;log_file = &quot;test.log&quot;class SingletonLogger(Singleton): def __init__(self): super(SingletonLogger, self).__init__() self.logger = logging.getLogger(app_name) format_str = &quot;[%(asctime)s][%(levelname)s]&gt; %(message)s&quot; formatter = logging.Formatter(format_str) file_handler = logging.FileHandler(log_file) file_handler.setFormatter(formatter) self.logger.addHandler(file_handler) self.logger.setLevel(logging.INFO) def debug(self, data): self.logger.debug(data) def info(self, data): self.logger.info(data) def warning(self, data): self.logger.warning(data) def error(self, data): self.logger.error(data)def test_log(): logger = SingletonLogger() #output the log msg logger.debug(&quot;this is the debug message&quot;) logger.info(&quot;this is the info message&quot;) logger.warning(&quot;this is the warning message&quot;) logger.error(&quot;this is the error message&quot;)","categories":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/tags/django/"},{"name":"log","slug":"log","permalink":"http://www.baidu.com/tags/log/"}],"author":"yuanfeng"},{"title":"hexo","slug":"hexo","date":"2019-04-05T09:36:34.000Z","updated":"2019-05-05T07:57:02.282Z","comments":true,"path":"2019/04/05/hexo/","link":"","permalink":"http://www.baidu.com/2019/04/05/hexo/","excerpt":"","text":"基本操作 文件/文件夹 说明 _config.yml 配置文件 public 生成的静态文件，这个目录最终会发布到服务器 scaffolds 一些通用的markdown模板 source 编写的markdown文件，_drafts草稿文件，_posts发布的文章 themes 博客的模板 常用命令 hexo new &quot;postName&quot; hexo new page &quot;pageName&quot; hexo server npm install hexo-cli -g hexo init blog cd blog npm install hexo server 创建一篇新的文章 hexo new [layout] &lt;title&gt; hexo有三种默认的布局：post,page,draft他们分别对应的路径如下|布局|路径||—|—||post|source/_posts||page|source||draft|source/_drafts| 提交到github安装git插件 npm install hexo-deployer-git --save git的配置，修改_config.yml文件 deploy: type: git repository: git@github.com:love-fengyuan/love-fengyuan.github.io.git branch: master 将代码push到github： hexo deploy 常见问题执行deploy命令了，但是代码未上传？ 先执行hexo generate命令，生成静态文件了，再执行hexo deploy上传，上传是只会上传public中生成的文件。 修改了模板，但是没有生效？ 修改了模板没有生效，建议先“hexo clean”，然后在“hexo generate”，只执行hexo generate，可能模板后者静态文件不会替换。 第二篇博客 hexo new title 修改显示路径，使用start路径来编辑它（如果是\\斜杠需换成/斜杠） hexo generate hexo deploy 查看博客 插入图片视频插入图片 ![k8sss](test/k8s_jg.png) 插入视频 &lt;video href=&apos;test/roam_1.mp4&apos; type=&apos;video/mp4&apos; controls=&apos;controls&apos; width=&apos;100%&apos; height=&apos;100%&apos;&gt;love&lt;/video&gt; {% raw %} {% endraw%} 参考官网：https://hexo.io/zh-cn/ https://www.jianshu.com/p/da491b249aee https://www.jianshu.com/p/a7cc54797ecc","categories":[{"name":"hexo","slug":"hexo","permalink":"http://www.baidu.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.baidu.com/tags/hexo/"}],"author":"yuanfeng"},{"title":"plan","slug":"plan","date":"2019-04-05T09:36:34.000Z","updated":"2019-05-03T17:52:52.569Z","comments":true,"path":"2019/04/05/plan/","link":"","permalink":"http://www.baidu.com/2019/04/05/plan/","excerpt":"","text":"planQ:web压力测试工具 A:Apache JMeter // Web Application Stress Tool // gatling // locust autoMysql / Mongodb / RedisTomact NginxKubernetes / Dockerpython shellAnsible/ Puppet / SaltStack / FabricZabbix/ Nagios / Cacti / Grafana / Prometheus / ELK /Kafka jenkins / gitlab / Lvs / HaproxyLAMP / LNMP/ DAS/SNA/NAS/","categories":[{"name":"plan other","slug":"plan-other","permalink":"http://www.baidu.com/categories/plan-other/"}],"tags":[{"name":"plan","slug":"plan","permalink":"http://www.baidu.com/tags/plan/"}],"author":"yuanfeng"},{"title":"ansible","slug":"ansible","date":"2019-03-10T15:06:52.000Z","updated":"2019-05-05T07:25:07.423Z","comments":true,"path":"2019/03/10/ansible/","link":"","permalink":"http://www.baidu.com/2019/03/10/ansible/","excerpt":"","text":"AnsibleAnsible 基础 ANSIBLE_CONFIG 环境变量，可以定义配置文件的位置 ./ansible.cfg 存在于当前工作目录 ~/.ansible.cfg 存在于当前用户家目录 /etc/ansible/ansible.cfg 默认目录 Ansible命令主机要求：windows除外 配置语言： yaml，json只有server role:ansible 可以重复使用的 Ansible: https://github.com/ansible/ansible 从release下载安装包 需要pip安装包的依赖 log： https://www.cnblogs.com/xielisen/p/6817807.html 查看文件个数：ls -l | grep ‘^-‘ | wc -l ##################################马哥 Ansible 文件传输命令执行：应用部署，配置管理，任务流编排 企业应用场景：开发，测试，发布，生产，灰度环境（基于主机，用户，地区） vie0 修改主机ip ansible -m pingm:模块ansible 127.0.0.1 -m ping 在 /etc/ansible/hosts中配置主机清单 测试网络通讯; ansible 192.168.1.101 -m ping -k 输入口令（密码）k: 密码认证建议基于key验证 etc/ssh/sshd_config ansible all -m ping all: 代表主机清单的所有主机 ansible.cfgansible.cfg forks=5 并发执行5 ansible-doc:显示模块命令 ansible websevers –list-hosts ansible all –list-host ansible debserver -m ping -u wang -k 以wang的身份去连接 ansible debserver -m command -a ‘ls /root’ -u wang -k -b -K以wang身份连接，切换到root用户权限，默认为root -K root口令 usermod -a -G wheel wang 将wang加入到组 K的口令;sudo中：取消下面一行的注释：%wheel ALL=(ALL) NOPASSWD:ALL 基于key验证 ssh-keygen ssh-copy-id 192.168.80.101 ssh-copy-id 192.168.80.102 ....... &amp; linux中表示后台执行 ansible all -m command -a “sleep 10”休眠10s command: ansible all -a ‘ls /data’ ansible all -a ‘df -h’ ansible-doc command creates 存在不执行 ansible all -a ‘removes=/etc/fs cat /etc/fstab’ removes 不存在不执行 ansible all -a ‘creates=/etc/fs cat /etc/fstab’ chdir 切换文件夹 ansible all -a ‘chdir=/root ls’ ansible 192.168.80.101 -a ‘/data/test.sh’ 执行该主机上/data/test.sh 注： 注意规范 #！/bin/bash 创建账号： ansible all -a &apos;useradd test1&apos; 查询： ansible all -a &apos;getent passwd test1&apos; command 命令对管道，重定向,变量 特殊符号支持有问题，建议shell shell： ansible all -m shell -a &apos;echo $HOSTNAME&apos; 更改口令: ansible all -m shell -a &apos;echo magedu|passwd --stdin test1&apos; script： chmod +x test.sh ansible all -m script -a ‘/root/ansible/test.sh’在所有主机上执行test.sh ansible all -a ‘getenforce’ cp /etc/sysconfig/selinux &gt;vim selinux copy:ansible-doc -s copy ansible all -m copy -a ‘src=/root/ansible/selinux dest=/etc/selinux/config backup=yes’文件复制 ansible all -m shell -a ‘getenforce’ ansible all -m copy -a ‘src=/etc/shadow dest=/data mode=000 owner=root’ ansible all -m copy -a ‘content=”hello\\n thanks \\n “ dest=/data/f2’直接写内容生成文件 fetch：从客户端去文件到服务器端，与copy相反 ansible all -m fetch -a ‘src=/var/log/messages dest=/data’从远程主机抓取log/message,到服务器，仅限单个文件 ansible all -m shell -a ‘tar jcf log.tar.xz /var/log/*.log’ 包的加压与解压archiveunarchive file： ansible all -m file -a ‘name=/data/f3 state=touch’ 创建文件 ansible all -m file -a ‘name=/data/f3 state=absent’ 删除文件 ansible all -a ‘ls -l /data’ ansible all -m file -a ‘name=/data/dir1 state=directory’ 创建文件夹，’state=absent’ 删除 ‘src=/etc/fstab dest=/data/fstab.link state=link’ 创建软连接 ‘dest=/data/fstab.link state=absent’ 删除软连接 ‘dest=/data/* state=absent’ 删除所有文件 ‘dest=/data/ state=absent’ 删除文件夹 不能删除挂载点上的 ansible 192.168.80.101 -m hostname -a ‘name=new_name’ 修改主机名 cron： ansible all -m cron -a ‘minute=* weekday=1,3,5 job=”/usr/bin/wall FBI warning” name=warningcron’ 创建定时报警任务，写入crontab ansible all -m cron -a ‘disabled=true job=”/usr/bin/wall FBI warning” name=warningcron’ 禁用此任务，必须加name ‘job=”/usr/bin/wall FBI warning” name=warningcron state=absent’ 删除 yum/etc/yum.repos/base.repo yum仓库配置 ansible all -m yum -a ‘name=vsftpd’安装多个软件用’,’隔开 ansible all -m yun -a ‘list=instealled’ 安装过的列表 ‘name=vsftpd state=removed’卸载 ‘name=vsftpd state=absent’ ‘rpm -q vsftpd’ 查找是否卸载 安装下载好的软件；ansible all -m copy -a ‘src=/data/softname dest=/root/‘ ansible all -a ‘ls /root/‘ ansbile all -m yum -a ‘name=/root/softname’ disable_gpg_check=yes 忽略，禁用 ‘name=dstat update_cache=yes’ 更新缓存 services: ansible all -m services -a ‘name=vsftpd state=started enabled=yes’启动服务，同时设为开机启动 user: ansible all -m user -a ‘name=nginx shell=/sbin/nologin system=yes home=/var/nginx groups=root,bin uid=80 comment=”nginx service”‘ 创建账号 ansible all -m user -a ‘name=nginx state=absent remove=yes’ 删除账号，删除home目录 group: ansible all -m group -a ‘name=nginx system=yes gid=80’ ansible all -a ‘getent group nginx’ ansible -m group -a ‘name=nginx state=absent’ 删除 ansible-galaxy: ansible-galaxy install geerlingguy.nginx yml/yaml: 注意缩进，格式 --- -hosts:webserver remote_user:root tasks: -name:hello command：hostname ansible-playbook test.yaml ansible-vault:ansible-vault encrypt test.yaml 对文件进行加密，避免敏感信息泄露 需要设置加密口令,再次执行yaml时会报错， ansible-vault decrypt test.yaml 解密 ansible-vault view test.yaml 查看yaml需要输入口令 ansible-vault rekey test.yaml 修改密码 ansible-vault create test2.yaml 创建新的playbook文件 ansible-console: 交互式：ansible-console “root@all (3)[f:5]$ “ 并发数量为5也可以修改forks 10 cd 192.168.80.135 切换到135主机 hostname name=node2.magedu.com 修改主机名 playbookplaybook采用YAMl语言编写 1.# test yaml 注释2.缩进必须统一 --- - hosts:webserver remote_user:root tasks: - name:create new file #描述 file:name=/data/newfile state=touch 模块/命令 - name:create new user user: name=test2 - name: install httpd yum:name=httpd - name:copy conf copy:src=/etc/conf dest=/etc/conf - name:start service service:name=httpd state=started enables=yes ansible-playbook -C file.yml # -C 检查 ansible all -a ‘getent passwd test2’ #查看test2用户 ansible all -m shell -a ‘ss -tln | grep :80’ #查看80端口 ansible all -a ‘getent passwd test2’ –limit 192.168.80.134 ansibel-playbook file.yml –list ansibel-playbook file.yml –list-tasks - name:copy a file copy:src=files/test.py dest=/etc/test.py #files相对路径，相对于当前目录 注：文件修改后再次执行copy，不会生效 更新配置文件，执行playbook后，并不会生效 http.yml --- - hosts: webserver remote_user:root tasks: - name:install https package yum:name-httpd - name: copy conf file copy: src=files/httpd.conf dest=/etc/httpd/conf baskup=yes - name: start service service: name=httpd state=started enabled=yes 执行http.yml，修改配置文件后，执行不会重启 http.yml --- - hosts: webserver remote_user:root tasks: - name:install https package yum:name-httpd tag:inshttpd - name: copy conf file copy: src=files/httpd.conf dest=/etc/httpd/conf baskup=yes notify:restart service - name: start service service: name=httpd state=started enabled=yes tag:rshttpd handlers: - name: restart service service: name=http state=restarted 也可以同时触发两个任务 tags： 添加标签，可以单独执行标签 多个动作共用一个标签 ansible-playbook -t rshttpd httpd.yml ansible-playbook -t inshttpd,rshttpd httpd.yml setup: ansible all -m setup -a ‘filter=ansible_hostname’ ansible all -m setup -a ‘filter=address‘\\ ansible all -m setup -a ‘filter=ansible_all_ipv4_address’ app.yml --- - hosts: webserver remote_user: root tasks: - name: install packing yum: name={{ pkname }} - name: start service service: name={{ pkname }} state=started enabled=yes ansible-playbook -e ‘pkname=httpd’ app.yml pkname 不会写死，灵活定义 也可以同时装多个包，用逗号隔开 eg： --- - hosts:websever remote_user: root vars: - pkname1: httpd - pkname2: vsftpd tasks: - name:install pachage yum: name={{ pkname1 }} - name: install package yum: name={{ pkname2 }} 定义变量在playbook中， hostname.yml: --- - hosts: webserver rempte_user: root tasks: - name: set hostname hostname: name= www{{http_port}}.magedu.com hosts： [webserver:vars] nodenamw=www domainname=magedu.com 此处的变量对webserver所有主机有效 tasks: - name: set hostname hostname：name={{nodename}}{{http_port}}.{{domasinname}} 命令行优先级高于配置文件 ansible all -m setupansible all -m setup -a ‘filter=”ansbile_fqdn”‘ var.yml --- - hosts:webserver renote_use: root tasks: - name: create a file file: name=/data/{{ ansible_fqdn }}.log state=touch mode=600 owner=wang ansible-playbook -c var.yml vars.yml var1: httpdvar2: vsftpd testvars.yml --- - hosts: webserver remote_user: root vars_file: - vars.yml tasks: - name：install package yum: name={{ var1 }} - name: create file file: name= /data/{{ var2 }}.log state=touch template.yml --- - hosts: webserver remote_user: root tasks: - name: install package tum: name=nginx - name: copy template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf - name start service service: name=nginx state=started enabled=yes ansible all -m shell -a ‘ss -ntpl’ #查看端口 nginx.conf中修改: worker_processes NaN #cpu个数的2次方 修改template.yml --- - hosts: webserver remote_user: root tasks: - name: install package tum: name=nginx - name: copy template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: start service - name start service service: name=nginx state=started enabled=yes handlers: - name: restart service service: name=nginx state=restarted ansible all -m shell -a ‘ps aux | grep nginx’ #过滤nginx进程 hosts：也可以写成如下模式 [webserver]192.168.80.134 http_port=81192.168.80.135 http_port=82 ansible-playbook -e ‘http_port=99’ testtemp.yml #修改端口 优先级：命令行&gt;playbook&gt;主机清单 ansibel all -m setup -a ‘filte=ansible_os_family’ ‘filter=”distribution“‘ testitem.yml --- - hosts: webserver remote_user: root tasks: - name: create some files file: name=/data/{{ item }} state=touch when: ansible_distribution_major_version == &quot;7&quot; with_items: - file1 - file2 - file3 - name: install spme package yum: name={{ item }} with_items: - htop - sl - hping3 create_group.yml --- - hosts: all remote_user: root tasks: - name: create some groups group: name={{ item }} when: ansible_distribution_major_version == &quot;7&quot; with_items: - g1 - g2 - g3 创建用户，并加入到组 --- - hosts: all remote_user: root tasks: - name: create some groups group: name={{ item }} when: ansible_distribution_major_version == &quot;7&quot; with_items: - g1 - g2 - g3 - name:create some users user: name={{item.name}} group={{item.group}} with_items: - { name: &apos;user1&apos;, group: &apos;g1&apos; } - { name: &apos;user2&apos;, group: &apos;g2&apos; } - { name: &apos;user3&apos;, group: &apos;g3&apos; } for: testfor.yml --- - hosts: all remote_user: root vars: ports: - 81 - 82 - 83 tasks: - name: copy conf template: src=for1.conf.j2 dest=/data/for1.conf 创建文件：for1.conf.j2 {% for port in ports %} server{ listen {{ port }} } {% endfor %} 修改为字典模式： --- - hosts: all remote_user: root vars: ports: - listen_port:81 - listen_port:82 - listen_port:83 tasks: - name: copy conf template: src=for2.conf.j2 dest=/data/for1.conf for2.conf.j2 {% for port in ports %} server{ listen {{ port.listen_port }} } {% endfor %} --- - hosts: all remote_user: root vars: ports: - web1: port: 81 name: web1.magedu.com rootdir: /data/website1 - web2: port: 83 name: web2.magedu.com rootdir: /data/website2 - web3: port: 83 name: web3.magedu.com rootdir: /data/website3 tasks: - name: copy conf template: src=for3.conf.j2 dest=/data/for1.conf for3.conf.j22 {% for p in ports %} server{ listen {{ p.port }} servername {{ p.name }} documentroot {{ p.rootdir }} } {% endfor %} --- - hosts: all remote_user: root vars: ports: - web1: port: 81 #name: web1.magedu.com rootdir: /data/website1 - web2: port: 83 name: web2.magedu.com rootdir: /data/website2 - web3: port: 83 #name: web3.magedu.com rootdir: /data/website3 tasks: - name: copy conf template: src=for4.conf.j2 dest=/data/for4.conf for4.conf.j22 {% for p in ports %} server{ listen {{ p.port }} {% if p.name is defined %} servername {{ p.name }} {% endif %} documentroot {{ p.rootdir }} } {% endfor %} roles创建roles文件夹： mkdir roles mkdir roles/{httpd, mysql, memcache} -pv mkdir roles/nginx ansible all -m shell -a ‘rpm -q nginx’ ‘getent group nginx’ ‘userdel -f nginx’ 删除用户，组 cd nginx mkdir tasks templates cd tasks vim group.yml - name:create group group: name=nginx gid=80 vim user.yml - name: create user user: name=nginx group=nginx system=yes shell=/sbin/nologin uid=80 vim yum.yml - name: install package yum: name=nginx vim start.yml - name: start service service: name=nginx state=started enabled=yes vim restart.yml - name: restart service sservice: name=nginx state=restarted templates: nginx.conf.j2(nginx.conf重命名为此) vim temp.yml - name: copy conf template: src=nginx.conf.j2 dest=/etc/ngiunx/nginx.conf vim main.yml - include: group.yml - include: user.yml - include: yum.yml - include: temp.yml - include: start.yml 调用的剧本与roles同级 vim nginx_role.yml - hosts: all remote_usr: root roles: - role: nginx ansibel-playbook -c nginx_role.yml httpd_roles mkdir tasks vim user.yml - name: create user user: name=apache system=yes shell=/sbin/nologin vim copyfile.yml - name: copy file file: src= dest= httpd： tasks： vim user.yml - name: create user user: name=apache system=yes shell=/sbin/nologin vim copyfile.yml - name: copy file copy: src=httpd.conf dest=/data/ vim main.yml - include: user.yml - include: copyfile.yml vim httpd_role.yml - hosts: all remote_user: root roles: - role: httpd 在一个角色中，调用另一个角色 vim some_role.yml - hosts: all remote_user：root roles: - role: http - role: nginx 一个角色引用另一个角色中的任务在main.yml中添加一行 - include: roles/httpd/tasks/copyfileyml 此处需要注意路径的选择 ansible.cfg 当playbook失败的情况下，一个重试文件将会创建，后缀为retry，默认开启此功能 添加标签：some_role.yml --- - hosts: all remote_user: root roles: - { role: httpd, tags:[&apos;web&apos;, &apos;httpd&apos;] } #即属于web，也属于httpd - { role: nginx, tags:[&apos;web&apos;, &apos;nginx&apos;] } ansible-playbook -t web some_role.yml #只执行标签web some_role.yml --- - hosts: all remote_user: root roles: - { role: httpd, tags:[&apos;web&apos;, &apos;httpd&apos;] } #即属于web，也属于httpd - { role: nginx, tags:[&apos;web&apos;, &apos;nginx&apos;] , when: ansible_distribution_major_version == &apos;7&apos;} # 当版本为7的时候执行 mkdir appcd appmkdir tasks templates vars handlers files task: vim group.yml - name: create group group: name=app system=yes gid=123 vim user.yml - name: create user user: name=app group=app system=yes shell=/sbin/nologin uid=1223 vim yum.yml - name: isntall package yum: name=httpd vim templ.yml - name: copy conf template: src=httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: restart service vars:main.yml username:app groupname: app handlers:vim main.yml - name: restart service service: name=httpd state=restarted tasks: vim start.yml - name: start service service: name=httpd state=started enabled=yes vim copyfile.yml - name: copy config copy: src=vhosts.conf dest=/etc/httpd/conf.d/ owner=app vim main.yml - include: group.yml - include: user.yml - include: yum.yml - include: templ.yml - include: copyfile.yml - include: start.yml files:touch vhosts.conf app_role.yml - hosts: all remote_user: root roles: - app memcached: yum install memcached cat /etc/sysconfig/memcached cp /etc/sysconfig/memcached templates/memcached.j2修改：CACHESIZE=”NaN“ vim tasks/yum.yml - name: install package yum: name=memcached vim taska/start.yml - name: start service service: name=memcached state=started enabled=yes vim /tasks/templ.yml - name: copy conf templates: src=memcached.j2 dest=/etc/sysconfig/memcached vim tasks/main.yml - include: yum.yml - include: templ.yml - include: start.yml vim memcached_role.yml - hosts: all remote_user: root roles: - memcached ansible-playbook -C memecached_role.yml ansible-playbook memcached_role.yml","categories":[{"name":"ansible","slug":"ansible","permalink":"http://www.baidu.com/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://www.baidu.com/tags/ansible/"}],"author":"yuanfeng"}]}
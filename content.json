{"meta":{"title":"永远在路上 生命不息 学习不止","subtitle":"请道上大佬，多多指教","description":null,"author":"YuanFeng","url":"http://www.baidu.com","root":"/"},"pages":[{"title":"tags","date":"2019-05-01T21:24:27.000Z","updated":"2019-05-01T15:04:59.023Z","comments":true,"path":"tags/index.html","permalink":"http://www.baidu.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-05-01T21:24:47.000Z","updated":"2019-05-01T15:06:01.430Z","comments":true,"path":"categories/index.html","permalink":"http://www.baidu.com/categories/index.html","excerpt":"","text":""},{"title":"achives","date":"2019-03-10T00:54:40.000Z","updated":"2019-05-01T15:31:29.938Z","comments":true,"path":"achives/index.html","permalink":"http://www.baidu.com/achives/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"zabbix","date":"2019-05-21T00:27:52.998Z","updated":"2019-05-21T00:27:52.998Z","comments":true,"path":"2019/05/21/zabbix/","link":"","permalink":"http://www.baidu.com/2019/05/21/zabbix/","excerpt":"","text":"zabbixzabbix介绍zabbix安装组件： zabbix server zabbix database zabbix web zabbix agent zabbix proxy： 可以代替 Zabbix server采集性能和可用性数据。Zabbix proxy在Zabbix的部署是可选部分；但是proxy的部署可以很好的分担单个Zabbix server的负载 数据流 定义 主机（host） 你想要监控的联网设备，有IP/DNS。 主机组（host group) 主机的逻辑组；可能包含主机和模板。一个主机组里的主机和模板之间并没有任何直接的关联。通常在给不同用户组的主机分配权限时候使用主机组。 监控项（item） 你想要从主机接收的特定数据，一个度量（metrics）/指标数据。 值预处理（value preprocessing） 存入数据库之前，转化/预处理接收到的指标数据 触发器（trigger） 触发器是一个逻辑表达式，用来定义问题阈值和“评估”监控项接收到的数据 当接收到的数据高于阈值时，触发器从“OK”变成“Problem”状态。当接收到的数据低于阈值时，触发器保留/返回“OK”的状态。 事件（event） 发生的需要注意的事件，例如触发器状态改变、自动发现/监控代理自动注册 事件标签（event tag） 提前设置的事件标记，可以用于事件关联，权限细化设置等。 事件关联（event correlation） 自动灵活的、精确的关联问题和解决方案 比如说，你可以定义触发器A告警的异常可以由触发器B解决，触发器B可能采用完全不同的数据采集方式。 异常（problems） 处在“异常”状态的触发器 异常状态更新（problem update） Zabbix提供的异常管理选项，例如添加评论、确认异常、改变严重级别或者手动关闭等。 动作（action） 预先定义的应对事件的动作 一个动作由操作(例如发出通知)和条件(什么时间进行操作)组成 升级（escalation） 用户自定义的一个在动作（action）内执行操作的场景; 发送通知/执行远程命令的序列。 媒介（media） 发送告警通知的方式、途径 告警通知（notification） 通过预先设定好的媒介途径发送事件信息给用户。 远程命令（remote command） 预定义好的，满足特定条件的情况下，可以在被监控主机上自动执行的命令。 模版（template） 被应用到一个或多个主机上的一整套实体组合（如监控项，触发器，图形，聚合图形，应用，LLD，Web场景等）。 模版的应用使得主机上的监控任务部署快捷方便；也可以使监控任务的批量修改更加简单。模版是直接关联到每台单独的主机上。 应用（application） 监控项的逻辑分组 Web场景（web scenario） 检查网站可浏览性的一个或多个HTTP请求 前端（frontend) Zabbix提供的web界面 仪表板（dashboard） 自定义的web前端模块中，用于重要的概要和可视化信息展示的单元， 我们称之为组件（widget）。 组件（widget） Dashboard中用来展示某种信息和数据的可视化组件（概览、map、图表、时钟等）。 Zabbix API Zabbix API允许用户使用JSON RPC协议来创建、更新和获取Zabbix对象（如主机、监控项、图表等）信息或者执行任何其他的自定义的任务 Zabbix server Zabbix软件的核心进程，执行监控操作，与Zabbix proxies和Agents进行交互、触发器计算、发送告警通知；也是数据的中央存储库 Zabbix agent 部署在监控对象上的进程，能够主动监控本地资源和应用 Zabbix proxy 代替Zabbix Server采集数据，从而分担Zabbix Server负载的进程 加密（encryption） 使用TLS（Transport Layer Security ）协议支持Zabbix组建之间的加密通讯(server, proxy, agent, zabbix_sender 和 zabbix_get工具) 。 网络自动发现（network discovery） 网络设备的自动发现。 低级别自动发现（low-level discovery） 特定设备上低级别实体的自动发现（如文件系统、网络接口等）。 低级别自动发现规则（low-level discovery rule） 为自动发现设备中低级别实体设定的一系列规则。 监控项原型（item prototype） 有特定变量的指标，用于自动发现。. 低级别自动发现执行之后，该变量将被实际自动发现的参数替换，该指标也自动开始采集数据。 触发器原型（trigger prototype） 有特定参数作为变量的触发器，用于自动发现。自动发现执行后该变量将被实际自动发现的参数替换，该触发器自动开始计算数据。 还有其他的一些Zabbix 实体原型也被用于自动发现中——图表原型，主机原型，主机组原型，应用原型。 agent自动注册（agent auto-registration） Zabbix agent自己自动注册为一个主机，并且开始监控的自动执行进程。","categories":[],"tags":[]},{"title":"zookeeper入门","slug":"zookeeper","date":"2019-05-20T22:30:43.000Z","updated":"2019-05-21T00:27:28.152Z","comments":true,"path":"2019/05/21/zookeeper/","link":"","permalink":"http://www.baidu.com/2019/05/21/zookeeper/","excerpt":"","text":"zookeeper介绍ZooKeeper是一种用于分布式应用程序的分布式开源协调服务。它公开了一组简单的原语，分布式应用程序可以构建这些原语，以实现更高级别的服务，以实现同步，配置维护以及组和命名。它被设计为易于编程，并使用在熟悉的文件系统目录树结构之后设计的数据模型。它在Java中运行，并且具有Java和C的绑定。 众所周知，协调服务很难做到。他们特别容易出现比赛条件和死锁等错误。ZooKeeper背后的动机是减轻分布式应用程序从头开始实施协调服务的责任 zookeeper_apiZooKeeper的设计目标之一是提供一个非常简单的编程接口。因此，它仅支持以下操作： create：在树中的某个位置创建一个节点 delete：删除节点 exists：测试某个位置是否存在节点 get data：从节点读取数据 set data：将数据写入节点 get children：检索节点的子节点列表 sync：等待传播数据 zookeeper安装docker安装zookeeper docker search zookeeper docker pull zookeeper #拉取镜像 docker run –privileged=true -d –name zookeeper –publish 2181:2181 -d zookeeper:latest #启动容器并添加映射 zookeeper的扩容与缩容扩容集群容错（奇偶数节点问题）如ZooKeeper入门指南中所述，容错群集设置至少需要三台服务器，强烈建议您使用奇数个服务器。 通常三台服务器对于生产安装来说已经足够了，但为了在维护期间获得最大可靠性，您可能希望安装五台服务器。使用三台服务器时，如果对其中一台服务器执行维护，则在维护期间，您很容易在其他两台服务器上发生故障。如果你有五个正在运行，你可以拿一个进行维护，并且知道如果其他四个中的一个突然失败你仍然可以。 参考：http://blog.itpub.net/31441024/viewspace-2212546/","categories":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://www.baidu.com/categories/zookeeper/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://www.baidu.com/tags/zookeeper/"}],"author":"yuanfeng"},{"title":"iptables入门","slug":"iptables","date":"2019-05-17T23:10:43.000Z","updated":"2019-05-21T00:27:15.091Z","comments":true,"path":"2019/05/18/iptables/","link":"","permalink":"http://www.baidu.com/2019/05/18/iptables/","excerpt":"","text":"iptables入门iptablesiptables常用参数 参数 作用 -P 设置默认策略 -F 清空规则链 -L 查看规则链 -A 在规则链素的末尾加入新的规则 -I num 在规则链素的头部加入新的规则 -D num 删除某一条规则 -s 匹配来源地址，加”!”表示除这个IP地址外 -d 匹配目标地址 –dport num 匹配目标端口号 –sport num 匹配来源端口号 iptables进行端口转发第一步:开启系统的转发功能 vim /etc/sysctl.conf 将net.ipv4.ip_forward=0 修改为 net.ipv4.ip_forward=1 编辑后使用命令让配置马上生效 sysxrl -p 第二步:iptables命令 iptables -t nat -A PREROUTING -p tcp --dport [端口号] -j DNAT --to-destination [目标IP] iptables -t nat -A PREROUTING -p udp --dport [端口号] -j DNAT --to-destination [目标IP] iptables -t nat -A POSTROUTING -p tcp -d [目标IP] --dport [端口号] -j SNAT --to-source [本地服务器IP] iptables -t nat -A POSTROUTING -p udp -d [目标IP] --dport [端口号] -j SNAT --to-source [本地服务器IP] 第三步:重启iptables使配置生效（仅适合Centos6，7默认没有安装iptables防火墙） service iptables save service iptables restart 多端口转发 多端口转发修改方案： ( 将本地服务器的 50000~65535 转发至目标 IP 为 1.1.1.1 的 50000~65535 端口 ) -A PREROUTING -p tcp -m tcp --dport 50000:65535 -j DNAT --to-destination 1.1.1.1 -A PREROUTING -p udp -m udp --dport 50000:65535 -j DNAT --to-destination 1.1.1.1 -A POSTROUTING -d 1.1.1.1/32 -p tcp -m tcp --dport 50000:65535 -j SNAT --to-source [本地服务器IP] -A POSTROUTING -d 1.1.1.1/32 -p udp -m udp --dport 50000:65535 -j SNAT --to-source [本地服务器IP] 不同端口号修改方案（使用本地服务器的60000端口来转发目标ip为1.1.1.1的50000端口） -A PREROUTING -p tcp -m tcp --dport 60000 -j DNAT --to-destination 1.1.1.1:50000 -A PREROUTING -p udp -m udp --dport 60000 -j DNAT --to-destination 1.1.1.1:50000 -A POSTROUTING -d 1.1.1.1/32 -p tcp -m tcp --dport 50000 -j SNAT --to-source [本地服务器IP] -A POSTROUTING -d 1.1.1.1/32 -p udp -m udp --dport 50000 -j SNAT --to-source [本地服务器IP] 主机内部端口重定向有时可能需要将访问主机的7979端口映射到8080端口，也可以iptables重定向完成 iptables -t nat -A PREROUTING -p tcp --dport 7979 -j REDIRECT --to-ports 8080 参考https://www.cnblogs.com/ccuc/p/7497440.htmlhttps://blog.csdn.net/e_wsq/article/details/79933232 https://www.cnblogs.com/itxiongwei/p/5871075.htmlhttps://blog.51cto.com/13677371/2094355（命令）","categories":[{"name":"iptables","slug":"iptables","permalink":"http://www.baidu.com/categories/iptables/"}],"tags":[{"name":"iptables","slug":"iptables","permalink":"http://www.baidu.com/tags/iptables/"}],"author":"yuanfeng"},{"title":"git服务器搭建","slug":"git_server","date":"2019-05-05T21:42:35.000Z","updated":"2019-05-05T13:44:03.676Z","comments":true,"path":"2019/05/06/git_server/","link":"","permalink":"http://www.baidu.com/2019/05/06/git_server/","excerpt":"","text":"Git服务器搭建github是免费托管代码开源的远程仓库。若不想公开代码，又不想付费，就只能创建自己的git服务器作为仓库使用。使用一台运行的linux的计算机，通过apt命令行就可以完成安装。 1.安装git安装git: sudo apt-get install git 创建一个git用户组和用户，用来运行git： groupadd git useradd git -g git 2.创建证书登录收集需要登录的用户的公钥，公钥位于id_rsa.pub文件中，把所有公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。如果没有该文件，创建它： $ cd /home/git/ $ mkdir .ssh $ chmod 755 .ssh $ touch .ssh/authorized_keys $ chmod 644 .ssh/authorized_keys 3.初始化仓库选定一个目录作为仓库，假定是/home/gitrepo/allen.git,在/home/gitrepo目录下输入命令： $ cd /home $ mkdir gitrepo $ chown git:git gitrepo/ $ cd gitrepo $ git init --bare allen.git Initialized empty Git repository in /home/gitrepo/allen.git/ 以上命令创建一个裸仓库，裸仓库没有工作区。因为服务器上的git是为了共享，不让用户直接登录到服务器上去修改工作区，并且服务器上的git仓库通常都以’.git’结尾，把owner改为git： $ sudo chown -R git:git allen.git 禁止shell登录出于安全考虑，前面创建的git用户不允许登录shell，这可以通过编辑/etc/passwd文件完成。 找到如下一行： git:x:1001:1001:,,,:/home/git:/bin/bash 改为： git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell 这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。 4.克隆仓库$ git clone git@192.168.45.4:/home/gitrepo/allen.git Cloning into &apos;allen&apos;... warning: You appear to have cloned an empty repository. Checking connectivity... done. 192.168.45.4为git所在服务器的ip，将其修改为自己的git服务器的ip即可。 管理公钥Gitosis 管理权限Gitolite","categories":[{"name":"git","slug":"git","permalink":"http://www.baidu.com/categories/git/"}],"tags":[{"name":"git","slug":"git","permalink":"http://www.baidu.com/tags/git/"},{"name":"server","slug":"server","permalink":"http://www.baidu.com/tags/server/"}],"author":"yuanfeng"},{"title":"Redis介绍与基本使用","slug":"redis","date":"2019-05-05T21:05:14.000Z","updated":"2019-05-05T13:31:52.935Z","comments":true,"path":"2019/05/06/redis/","link":"","permalink":"http://www.baidu.com/2019/05/06/redis/","excerpt":"","text":"1.Redis 介绍实现缓存的方式，有多种，本地内存缓存，数据库缓存，文件系统缓存。这里介绍使用Redis数据库进行缓存。Redis是什么？ ​ REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。 ​ Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 ​ 它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 Redis 简介 Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据(memcache)，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 2.Redis 优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 3.安装Redis wget http://download.redis.io/releases/redis-3.2.6.tar.gz 解压： tar -zxvf redis-3.2.6.tar.gz cd redis-3.2.6 编译： cd redis-3.2.6 #进入目录make #编译 设置redis mkdir /usr/local/redis #创建redis操作目录cp src/redis-server src/redis-cli /usr/local/redis/bin/ #复制redis服务和命令cp redis.conf /usr/local/redis/conf #复制redis配置文件cd /usr/local/redis./bin/redis-server conf/redis.conf &amp; #后台启动redis 创建快捷键 vim ~/.bashrcalias redis=’/usr/local/redis/bin/redis-cli’ #添加快捷键source ~/.bashrc #使生效 redis远程连接 redis-cli -h 172.16.245.xxx -p 6379 redis 172.16.245.179:6379&gt; 安装验证成功！ 4.配置文件redis.conf 配置项说明如下： Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 ​ daemonize no 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 ​ pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 ​ port 6379 绑定的主机地址 ​ bind 127.0.0.1 当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 ​ timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose ​ loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null ​ logfile stdout 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id ​ databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 ​ save ​ Redis默认配置文件中提供了三个条件： ​ save 900 1 save 300 10 save 60 10000 ​ 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 ​ rdbcompression yes 指定本地数据库文件名，默认值为dump.rdb ​ dbfilename dump.rdb 指定本地数据库存放目录 ​ dir ./ 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 ​ slaveof 当master服务设置了密码保护时，slav服务连接master的密码 ​ masterauth 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭 ​ requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 ​ maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 ​ maxmemory 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no ​ appendonly no 指定更新日志文件名，默认为appendonly.aof ​ appendfilename appendonly.aof 指定更新日志条件，共有3个可选值：​ no：表示等操作系统进行数据缓存同步到磁盘（快）​ always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）​ everysec：表示每秒同步一次（折衷，默认值） ​ appendfsync everysec 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） ​ vm-enabled no 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 ​ vm-swap-file /tmp/redis.swap 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 ​ vm-max-memory 0 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 ​ vm-page-size 32 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 ​ vm-pages 134217728 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 ​ vm-max-threads 4 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 ​ glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 ​ hash-max-zipmap-entries 64 hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） ​ activerehashing yes 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 ​ include /path/to/local.conf 查看配置信息 1redis 127.0.0.1:6379&gt; CONFIG GET * 5.Redis数据类型String（字符串）​ string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。 string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。 string类型是Redis最基本的数据类型，一个键最大能存储512MB。 实例1234redis 127.0.0.1:6379&gt; SET name &quot;1000phone&quot;OKredis 127.0.0.1:6379&gt; GET name&quot;1000phone&quot; Hash（哈希）Redis hash 是一个键值(key=&gt;value)对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 实例123456redis&gt; HMSET myhash field1 &quot;Hello&quot; field2 &quot;World&quot;&quot;OK&quot;redis&gt; HGET myhash field1&quot;Hello&quot;redis&gt; HGET myhash field2&quot;World&quot; redis 172.16.245.179:6379&gt; hgetall myhash1) “fd1”2) “value1”3) “fd2”4) “value2”5) “fd3”6) “value2” fd1 fd2 fd3 value1 value2 value3 List（列表）Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。 实例1234567891011redis 127.0.0.1:6379&gt; lpush name redis(integer) 1redis 127.0.0.1:6379&gt; lpush name mongodb(integer) 2redis 127.0.0.1:6379&gt; lpush name rabitmq(integer) 3redis 127.0.0.1:6379&gt; lrange name 0 101) &quot;rabitmq&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;redis 127.0.0.1:6379&gt; rpop name Set（集合）Redis的Set是string类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 sadd 命令添加一个 string 元素到 key 对应的 set 集合中，成功返回1，如果元素已经在集合中返回 0，如果 key 对应的 set 不存在则返回错误。 1sadd key member 实例12345678910111213redis 127.0.0.1:6379&gt; sadd name redis(integer) 1redis 127.0.0.1:6379&gt; sadd name mongodb(integer) 1redis 127.0.0.1:6379&gt; sadd name rabitmq(integer) 1redis 127.0.0.1:6379&gt; sadd name rabitmq(integer) 0redis 127.0.0.1:6379&gt; smembers name1) &quot;redis&quot;2) &quot;rabitmq&quot;3) &quot;mongodb&quot; zset(sorted set：有序集合)Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 zadd 命令添加元素到集合，元素在集合中存在则更新对应score 1zadd key score member 实例123456789101112redis 127.0.0.1:6379&gt; zadd runoob 0 redis(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 mongodb(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 1redis 127.0.0.1:6379&gt; zadd runoob 0 rabitmq(integer) 0redis 127.0.0.1:6379&gt; &gt; ZRANGEBYSCORE runoob 0 10001) &quot;mongodb&quot;2) &quot;rabitmq&quot;3) &quot;redis&quot; 6.Redis发布订阅与事务发布与订阅​Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 Redis 客户端可以订阅任意数量的频道。 ​下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系： redis订阅 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： redis发布 实例以下实例演示了发布订阅是如何工作的。在我们实例中我们创建了订阅频道名为 redisChat: 123456redis 127.0.0.1:6379&gt; SUBSCRIBE redisChatReading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;redisChat&quot;3) (integer) 1 现在，我们先重新开启个 redis 客户端，然后在同一个频道 redisChat 发布两次消息，订阅者就能接收到消息。 123456789101112131415redis 127.0.0.1:6379&gt; PUBLISH redisChat &quot;Redis is a great caching technique&quot;(integer) 1redis 127.0.0.1:6379&gt; PUBLISH redisChat &quot;Learn redis by runoob.com&quot;(integer) 1# 订阅者的客户端会显示如下消息1) &quot;message&quot;2) &quot;redisChat&quot;3) &quot;Redis is a great caching technique&quot;1) &quot;message&quot;2) &quot;redisChat&quot;3) &quot;Learn redis by runoob.com&quot; Redis 事务Redis 事务可以一次执行多个命令， 并且带有以下两个重要的保证： 批量操作在发送 EXEC 命令前被放入队列缓存。收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。 一个事务从开始到执行会经历以下三个阶段： 开始事务。命令入队。执行事务。 redis事务 实例以下是一个事务的例子， 它先以 MULTI开始一个事务， 然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令： redis 127.0.0.1:6379&gt; MULTI OK redis 127.0.0.1:6379&gt; SET book-name “Mastering C++ in 21 days” QUEUED redis 127.0.0.1:6379&gt; GET book-name QUEUED redis 127.0.0.1:6379&gt; SADD tag “C++” “Programming” “Mastering Series” QUEUED redis 127.0.0.1:6379&gt; SMEMBERS tag QUEUED redis 127.0.0.1:6379&gt; EXEC 1) OK 2) “Mastering C++ in 21 days” 3) (integer) 3 4) 1) “Mastering Series” 2) “C++” 3) “Programming” 单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。 比如：1234567891011121314151617181920212223redis 127.0.0.1:7000&gt; multiOKredis 127.0.0.1:7000&gt; set a aaaQUEUEDredis 127.0.0.1:7000&gt; set b bbbQUEUEDredis 127.0.0.1:7000&gt; set c cccQUEUEDredis 127.0.0.1:7000&gt; exec1) OK2) OK3) OK 如果在 set b bbb 处失败，set a 已成功不会回滚，set c 还会继续执行。 7.Python操作Redis安装redis-py1pip install redis redis-py 的API的使用可以分类为： 连接方式 连接池 操作 String 操作 Hash 操作 List 操作 Set 操作 Sort Set 操作 管道 redis-py提供两个类Redis和StrictRedis用于实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令，Redis是StrictRedis的子类 12345import redisr = redis.Redis(host=&apos;192.168.49.130&apos;, port=6379)r.set(&apos;foo&apos;, &apos;Bar&apos;)print r.get(&apos;foo&apos;) 创建连接池: redis-py使用connection pool来管理对一个redis server的所有连接，避免每次建立、释放连接的开销。默认，每个Redis实例都会维护一个自己的连接池。可以直接建立一个连接池，然后作为参数Redis，这样就可以实现多个Redis实例共享一个连接池。 [ 复制代码](https://common.cnblogs.com/images/copycode.gif) 12345678import redis pool = redis.ConnectionPool(host=&apos;192.168.49.130&apos;, port=6379) r = redis.Redis(connection_pool=pool)#r = redis.StrictRedis(connection_pool=pool) #StrictRedis也是支持的r.set(&apos;foo&apos;, &apos;Bar&apos;)print r.get(&apos;foo&apos;) MySQL数据有两种存储引擎： MyISAM — 表锁 INONDB — 表行锁 ———这种存储方式推荐使用， 支持事务 8.应用场景案例（1）页面点击数​ 假定我们对一系列页面需要记录点击次数。例如论坛的每个帖子都要记录点击次数，而点击次数比回帖的次数的多得多。如果使用关系数据库来存储点击，可能存在大量的行级锁争用。所以，点击数的增加使用redis的INCR命令最好不过了。 ​ 当redis服务器启动时，可以从关系数据库读入点击数的初始值（1237这个页面被访问了34634次） 123&gt;&gt;&gt; r.set(&quot;visit:1237:totals&quot;,34634)True 每当有一个页面点击，则使用INCR增加点击数即可。 12345678910111213&gt;&gt;&gt; r.incr(&quot;visit:1237:totals&quot;)34635&gt;&gt;&gt; r.incr(&quot;visit:1237:totals&quot;)34636页面载入的时候则可直接获取这个值&gt;&gt;&gt; r.get (&quot;visit:1237:totals&quot;)&apos;34636&apos; （2）使用hash类型保存多样化对象，类似二维表结构当有大量类型文档的对象，文档的内容都不一样时，（即“表”没有固定的列），可以使用hash来表达。 1234567891011121314151617181920212223&gt;&gt;&gt; r.hset(&apos;users:jdoe&apos;, &apos;name&apos;, &quot;John Doe&quot;)1L&gt;&gt;&gt; r.hset(&apos;users:jdoe&apos;, &apos;email&apos;, &apos;John@test.com&apos;)1L&gt;&gt;&gt; r.hset(&apos;users:jdoe&apos;, &apos;phone&apos;, &apos;1555313940&apos;)1L&gt;&gt;&gt; r.hincrby(&apos;users:jdoe&apos;, &apos;visits&apos;, 1)1L&gt;&gt;&gt; r.hgetall(&apos;users:jdoe&apos;)&#123;&apos;phone&apos;: &apos;1555313940&apos;, &apos;name&apos;: &apos;John Doe&apos;, &apos;visits&apos;: &apos;1&apos;, &apos;email&apos;: &apos;John@test.com&apos;&#125;&gt;&gt;&gt; r.hkeys(&apos;users:jdoe&apos;)[&apos;name&apos;, &apos;email&apos;, &apos;phone&apos;, &apos;visits&apos;] （3）社交圈子数据​在社交网站中，每一个圈子(circle)都有自己的用户群。通过圈子可以找到有共同特征（比如某一体育活动、游戏、电影等爱好者）的人。当一个用户加入一个或几个圈子后，系统可以向这个用户推荐圈子中的人。​我们定义这样两个圈子,并加入一些圈子成员。 123456789101112&gt;&gt;&gt; r.sadd(&apos;circle:game:lol&apos;,&apos;user:debugo&apos;)1&gt;&gt;&gt; r.sadd(&apos;circle:game:lol&apos;,&apos;user:leo&apos;)1&gt;&gt;&gt; r.sadd(&apos;circle:game:lol&apos;,&apos;user:Guo&apos;)1&gt;&gt;&gt; r.sadd(&apos;circle:soccer:InterMilan&apos;,&apos;user:Guo&apos;)1&gt;&gt;&gt; r.sadd(&apos;circle:soccer:InterMilan&apos;,&apos;user:Levis&apos;)1&gt;&gt;&gt; r.sadd(&apos;circle:soccer:InterMilan&apos;,&apos;user:leo&apos;)1 获取一个圈子的成员 12&gt;&gt;&gt; r.smembers(&apos;circle:game:lol&apos;)set([&apos;user:Guo&apos;, &apos;user:debugo&apos;, &apos;user:leo&apos;]) 可以使用集合运算来得到几个圈子的共同成员： 1234&gt;&gt;&gt; r.sinter(&apos;circle:game:lol&apos;, &apos;circle:soccer:InterMilan&apos;)set([&apos;user:Guo&apos;, &apos;user:leo&apos;])&gt;&gt;&gt; r.sunion(&apos;circle:game:lol&apos;, &apos;circle:soccer:InterMilan&apos;)set([&apos;user:Levis&apos;, &apos;user:Guo&apos;, &apos;user:debugo&apos;, &apos;user:leo&apos;])","categories":[{"name":"redis","slug":"redis","permalink":"http://www.baidu.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://www.baidu.com/tags/redis/"}],"author":"yuanfeng"},{"title":"django","slug":"django","date":"2019-05-05T20:38:32.000Z","updated":"2019-05-05T12:56:58.488Z","comments":true,"path":"2019/05/06/django/","link":"","permalink":"http://www.baidu.com/2019/05/06/django/","excerpt":"","text":"NULL","categories":[],"tags":[],"author":"yuanfeng"},{"title":"nginx","slug":"nginx","date":"2019-05-05T19:56:58.000Z","updated":"2019-05-05T12:18:50.862Z","comments":true,"path":"2019/05/06/nginx/","link":"","permalink":"http://www.baidu.com/2019/05/06/nginx/","excerpt":"","text":"Nginx服务Nginx现状​nginx 是当前的使用最广泛的webserver ,支持http正向/反向代理，支持TCP/UDP层代理，nginx在全部网站中占比较高，而且一直在增加。当下最时尚的webserver非nginx莫属。 Nginx特点 性能好 非阻塞IO/高并发(asyncio/aiohttp),支持文件IO 多worker，thread pool（线程池- 线程队列） 基于rbtree的定时器 系统特性的持续支持 功能强大 webserver/cache/keepalive/pipeline等等 各种upstream的支持【fastcgi/http/…】 输出灵活【chunk/zip/…】 在不断的发展 http2,tcp,udp,proxy… 运维的友好【这个对于开发和部署很重要】 配置非常规范【个人认为：约定及规范是最好的实践】 热加载和热更新【后文会详细介绍，能在二进制的层面热更新】 日志强大【真的很强的，很多变量支撑】 扩展强大 ​ 下图是nginx、apache和lighttpd的一个对比。系统压力，内存占用，upstream支持等多个方面都非常不错[ nginx对比图](nginx/nginx_compare.png) HTTPS = HTTP + SSL Nginx工作原理​Nginx的运行方式：master-worker多进程模式运行，单线程/非阻塞执行 ​Nginx 启动后生成master，master会启动conf数量的worker进程，当用户的请求过来之后，由不同的worker调起执行线程，非阻塞的执行请求。这种运行方式相对于apache的进程执行相对轻量很多，支撑的并发性也会高很多。 ​Nginx 默认采用守护模式启动，守护模式让master进程启动后在后台运行。在Nginx运行期间主要由一个master主进程和多个worker进程（worker数目一般与cpu数目相同） (1)master主进程 master主进程主要是管理worker进程，对网络事件进行收集和分发： 接收来自外界的信号 向各worker进程发送信号 监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程 (2)worker 工作进程​ nginx用一个独立的worker进程来处理一个请求，一个worker进程可以处理多个请求： ​ a. 当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接。 ​ b. 一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。采用这种方式的好处： 节省锁带来的开销。对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查上时，也会方便很多 独立进程，减少风险。 采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快重新启动新的worker进程。 在一次请求里无需进程切换 (3) Nginx的IO处理过程​一般的Tcp Socket处理过程： ​服务端：fd = socket.socket —&gt; fd.bind() —&gt; fd.listen() —&gt; accept() 等待客户端连接 —&gt; send / recv —&gt; close() 客户端：fd = socket.socket —&gt; fd.connect() 与服务端建立连接 —&gt; recv / send —&gt; close() ​Nginx的网络IO处理通常使用epoll，epoll函数使用了I/O复用模型。与I/O阻塞模型比较，I/O复用模型的优势在于可以同时等待多个（而不只是一个）套接字描述符就绪。Nginx的epoll工作流程如下： master进程先建好需要listen的socket后，然后再fork出多个woker进程，这样每个work进程都可以去accept这个socket 当一个client连接到来时，所有accept的work进程都会受到通知，但只有一个进程可以accept成功，其它的则会accept失败，Nginx提供了一把共享锁accept_mutex来保证同一时刻只有一个work进程在accept连接，从而解决惊群问题。 当一个worker进程accept这个连接后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完成的请求就结束了. Nginx 安装与配置​Nginx服务学习我们借助于一个第三方库Openresty，它本身就是把nginx核心代码做了一层封装，你完全可以把它当成Nginx使用。 ​OpenResty 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。 ​OpenResty 的目标是让你的Web服务直接跑在 Nginx 服务内部，充分利用 Nginx 的非阻塞 I/O 模型，不仅仅对 HTTP 客户端请求,甚至于对远程后端诸如 MySQL、PostgreSQL、Memcached 以及 Redis 等都进行一致的高性能响应。 Openresty下载页： https://openresty.org/cn/download.html 下载版本：wget https://openresty.org/download/openresty-1.11.2.5.tar.gz (Ubuntu 16.x) 最新版本： wget https://openresty.org/download/openresty-1.13.6.2.tar.gz (Ubuntu 17.10) 性能测试工具 Apache AB test 安装过程： （1）安装依赖库： sudo apt install libpcre3 libpcre3-dev sudo apt install openssl libssl-dev （2）安装openresty 123456789#将openresty安装到/opt/openresty目录下sudo mkdir /opt/openresty #修改组和用户权限 apple用户名 : apple组sudo chown -Rf apple:apple /opt/openresty/tar -xzvf openresty-1.11.2.5.tar.gzcd openresty-1.11.2.5 ./configure --prefix=/opt/openresty (注:./configure --help 查看更多的配置选项)makemake install 至此，安装完成，安装openresty就在/opt/openresty目录下。 （3）目录介绍 bin openresty 的启动文件 COPYRIGHT 版权文件 luajit lua虚拟环境luajit lualib lua实现的第三方库，包括redis， mysql， upload， upstream，websocket等等。 nginx nginx核心功能块 pod resty.index site ​openresty不只是提供了nginx功能，而且提供了丰富的工具集，我们可以做除了负载均衡和反向代理之外的很多事情，快速搭建出高性能web服务。 查看进程和端口： ps -ef | grep 80 netstat -tunpl | grep 80 # 修改 vim /opt/openresty/nginx/conf/nginx.conf 中，将listen 80改成 8080 启动nginx服务： $ /opt/openresty/nginx/sbin/nginx 打开页面：http://172.16.245.180:8080/ ​ http://localhost:8080/ 可以看到 Welcome to OpenResty ！ 的页面，表示已经安装成功！ 如果之前已安装了nginx 删除或停止它的服务： ​sudo apt remove nginx 或 ​sudo servie nginx stop 5 OpenResty 使用配置文件Openresty 框架的配置和nginx配置方法一样，配置文件: /opt/openresty/nginx/conf/nginx.conf ​Nginx主要通过nginx.conf文件进行配置使用。在nginx.conf文件中主要分为： 全局块：一些全局的属性，在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等 event块：参考事件模型，单个进程最大连接数等 http块：设定http服务器 server块：配置虚拟主机 location块：配置请求路由及页面的处理情况等 关键参数说明： nginx进程数，建议设置为等于CPU总核心数。 worker_processes 8; 全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] error_log /usr/local/nginx/logs/error.log info; 进程pid文件 pid /opt/openresty/nginx/logs/nginx.pid; 指定进程可以打开的最大描述符：数目 工作模式与连接数上限 这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 worker_rlimit_nofile 65535; 虚拟主机的配置12345678910111213141516171819202122232425server&#123; #监听端口 listen 80; #域名可以有多个，用空格隔开, cat /etc/hosts server_name www.jd.com jd.com; index index.html index.htm index.php; root /data/www/jd; #url 请求路由 location /hello &#123; default_type text/html; content_by_lua &apos; ngx.say(&quot;&lt;p&gt;Hello, World!&lt;/p&gt;&quot;) &apos;; &#125;&#125;#负载均衡配置upstream piao.jd.com &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weight参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3;&#125; 启动测试拷贝我们的工程文件 artproject.zip，解压到某一个目录 eg: /home/apple根目录下 配置nginx配置文件nginx.conf，添加如下信息： 1234567891011121314location /hello&#123; default_type text/html; content_by_lua &apos; ngx.say(&quot;&lt;p&gt;Hello, World!&lt;/p&gt;&quot;)&apos;;&#125;# 静态文件，nginx自己处理location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root /home/apple/artproject/art; # 过期1天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 1d;&#125; $ /opt/openresty/nginx/sbin/nginx -s stop, quit, reopen, reload $ /opt/openresty/nginx/sbin/nginx -t 测试 nginx: the configuration file /opt/openresty/nginx/conf/nginx.conf syntax is ok nginx: configuration file /opt/openresty/nginx/conf/nginx.conf test is successful 查看页面效果 http://172.16.245.180:8080/hello http://172.16.245.180:8080/static/admin/pages/index.html 负载均衡策略​负载均衡也是Nginx常用的一个功能，负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。 ​Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略 RR （轮询策略）​按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。 权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 1234upstream test&#123; server localhost:8080 weight=9; server localhost:8081 weight=1;&#125; 此时8080和8081分别占90%和10%。 ip_hash上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream test &#123; ip_hash; server localhost:8080; server localhost:8081;&#125; fair(第三方) 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream backend &#123; fair; server localhost:8080; server localhost:8081;&#125; url_hash(第三方) 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。 123456upstream backend &#123; hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081;&#125; 处理动态请求转发到某一个服务12345​ location = / &#123; ​ proxy_pass http://localhost:8080 ​ &#125; ​此处的proxy_pass 对应的服务，会导到上述upstream入口 作为静态资源服务器​Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作（CDN），这就是网站静态化处理的核心思路。 123456# 静态文件，nginx自己处理location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root /home/apple/artproject/art; # 过期1天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。 expires 1d;&#125; 关于URL路由规则语法规则：1234567location [=|~|~*|^~] /uri/ &#123; ​ … &#125; = 开头表示精确匹配 ^~ 开头表示uri以某个常规字符串开头，理解为匹配 url路径即可。 ~ 开头表示区分大小写的正则匹配 ~* 开头表示不区分大小写的正则匹配 !~和!~*分别为区分大小写不匹配及不区分大小写不匹配 的正则 / 通用匹配，任何请求都会匹配到。 多个location配置的情况下匹配顺序为： 首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。 例子，有如下匹配规则： 123456789101112131415161718192021222324location = / &#123; #规则A&#125;location = /login &#123; #规则B&#125;location ^~ /static/ &#123; #规则C&#125;location ~ \\.(gif|jpg|png|js|css)$ &#123; #规则D&#125;location ~* \\.png$ &#123; #规则E&#125;location !~ \\.xhtml$ &#123; #规则F&#125;location !~* \\.xhtml$ &#123; #规则G&#125;location / &#123; #规则H&#125; 那么产生的效果如下: 访问根目录/， 比如http://localhost/ 将匹配规则A访问 http://localhost/login 将匹配规则B，http://localhost/register 则匹配规则H访问 http://localhost/static/a.html 将匹配规则C访问 http://localhost/a.gif, http://localhost/b.jpg 将匹配规则D和规则E，但是规则D顺序优先，规则E不起作用，而 http://localhost/static/c.png 则优先匹配到规则C访问 http://localhost/a.PNG 则匹配规则E，而不会匹配规则D，因为规则E不区分大小写。 访问 http://localhost/a.xhtml 不会匹配规则F和规则G，http://localhost/a.XHTML不会匹配规则G，因为不区分大小写。规则F，规则G属于排除法，符合匹配规则但是不会匹配到，所以想想看实际应用中哪里会用到。 访问 http://localhost/category/id/1111 则最终匹配到规则H，因为以上规则都不匹配，这个时候应该是nginx转发请求给后端应用服务器，比如FastCGI（php），tomcat（jsp），nginx作为方向代理服务器存在。","categories":[{"name":"nginx","slug":"nginx","permalink":"http://www.baidu.com/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://www.baidu.com/tags/nginx/"}],"author":"yuanfeng"},{"title":"python设计模式","slug":"python_design_pattern","date":"2019-05-05T19:27:52.000Z","updated":"2019-05-05T11:31:54.825Z","comments":true,"path":"2019/05/06/python_design_pattern/","link":"","permalink":"http://www.baidu.com/2019/05/06/python_design_pattern/","excerpt":"","text":"七大设计原则七大设计原则： 1、单一职责原则【SINGLE RESPONSIBILITY PRINCIPLE】：一个类负责一项职责. 2、里氏替换原则【LISKOV SUBSTITUTION PRINCIPLE】：继承与派生的规则.（子类可替换父类） 3、依赖倒转原则【DEPENDENCE INVERSION PRINCIPLE】：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。即针对接口编程，不要针对实现编程。 4、接口隔离原则【INTERFACE SEGREGATION PRINCIPLE】：建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。 5、迪米特法则【LOW OF DEMETER】：高内聚 低耦合 – high cohesion low coupling 6、开闭原则【OPEN CLOSE PRINCIPLE】：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。 7、组合/聚合复用原则【Composition/Aggregation Reuse Principle(CARP) 】：尽量使用组合和聚合少使用继承的关系来达到复用的原则。 二十四种模式创建型模式 1、抽象工厂模式(Abstract factory pattern): 提供一个接口, 用于创建相关或依赖对象的家族, 而不需要指定具体类. 2、生成器模式(Builder pattern): 使用生成器模式封装一个产品的构造过程, 并允许按步骤构造. 将一个复杂对象的构建与它的表示分离, 使得同样的构建过程可以创建不同的表示. 3、工厂模式(factory method pattern): 定义了一个创建对象的接口, 但由子类决定要实例化的类是哪一个. 工厂方法让类把实例化推迟到子类. 4、原型模式(prototype pattern): 当创建给定类的实例过程很昂贵或很复杂时, 就使用原形模式. 5、单例了模式(Singleton pattern): 确保一个类只有一个实例, 并提供全局访问点. 6、多例模式(Multition pattern): 在一个解决方案中结合两个或多个模式, 以解决一般或重复发生的问题. 结构型模式 1、适配器模式(Adapter pattern): 将一个类的接口, 转换成客户期望的另一个接口. 适配器让原本接口不兼容的类可以合作无间. 对象适配器使用组合, 类适配器使用多重继承. 2、桥接模式(Bridge pattern): 使用桥接模式通过将实现和抽象放在两个不同的类层次中而使它们可以独立改变. 3、组合模式(composite pattern): 允许你将对象组合成树形结构来表现”整体/部分”层次结构. 组合能让客户以一致的方式处理个别对象以及对象组合. 4、装饰者模式(decorator pattern): 动态地将责任附加到对象上, 若要扩展功能, 装饰者提供了比继承更有弹性的替代方案. 5、外观模式(facade pattern): 提供了一个统一的接口, 用来访问子系统中的一群接口. 外观定义了一个高层接口, 让子系统更容易使用. 6、亨元模式(Flyweight Pattern): 如想让某个类的一个实例能用来提供许多”虚拟实例”, 就使用蝇量模式. 7、代理模式(Proxy pattern): 为另一个对象提供一个替身或占位符以控制对这个对象的访问. 行为型模式 1、责任链模式(Chain of responsibility pattern): 通过责任链模式, 你可以为某个请求创建一个对象链. 每个对象依序检查此请求并对其进行处理或者将它传给链中的下一个对象. 2、命令模式(Command pattern): 将”请求”封闭成对象, 以便使用不同的请求,队列或者日志来参数化其他对象. 命令模式也支持可撤销的操作. 3、解释器模式(Interpreter pattern): 使用解释器模式为语言创建解释器. 4、迭代器模式(iterator pattern): 提供一种方法顺序访问一个聚合对象中的各个元素, 而又不暴露其内部的表示. 5、中介者模式(Mediator pattern) : 使用中介者模式来集中相关对象之间复杂的沟通和控制方式. 6、备忘录模式(Memento pattern): 当你需要让对象返回之前的状态时(例如, 你的用户请求”撤销”), 你使用备忘录模式. 7、观察者模式(observer pattern): 在对象之间定义一对多的依赖, 这样一来, 当一个对象改变状态, 依赖它的对象都会收到通知, 并自动更新. 8、状态模式(State pattern): 允许对象在内部状态改变时改变它的行为, 对象看起来好象改了它的类. 9、策略模式(strategy pattern): 定义了算法族, 分别封闭起来, 让它们之间可以互相替换, 此模式让算法的变化独立于使用算法的客户. 10、模板方法模式(Template pattern): 在一个方法中定义一个算法的骨架, 而将一些步骤延迟到子类中. 模板方法使得子类可以在不改变算法结构的情况下, 重新定义算法中的某些步骤. 11、访问者模式(visitor pattern): 当你想要为一个对象的组合增加新的能力, 且封装并不重要时, 就使用访问者模式. 参考https://blog.csdn.net/weixin_41781973/article/details/80630337 https://www.cnblogs.com/beijiguangyong/archive/2010/11/15/2302807.html#4130080 https://www.cnblogs.com/Liqiongyu/p/5916710.html https://github.com/w392807287/Design_pattern_of_python","categories":[],"tags":[],"author":"yuanfeng"},{"title":"django中的cookie，session","slug":"django_cookie_session","date":"2019-05-01T19:30:43.000Z","updated":"2019-05-05T13:03:41.578Z","comments":true,"path":"2019/05/02/django_cookie_session/","link":"","permalink":"http://www.baidu.com/2019/05/02/django_cookie_session/","excerpt":"","text":"Django中的cookie和sessionCookies ：是浏览器为 Web 服务器存储的一小段信息。 每次浏览器从某个服务器请求页面时，它收到服务器回发送过来的cookies。它保存在浏览器下的某个文件夹下。 Session：Django的Session机制会向请求的浏览器发送cookie字符串。同时也会保存到本地一份，用来验证浏览器登录是否为同一用户。它存在于服务器，Django默认会把session存入到数据库中。 Session依赖于Cookie，如果浏览器不能保存cookies那么session就失效了。因为它需要浏览器的cookie值去session里做对比。session就是用来在服务器端保存用户的会话状态。 Cookie1、获取Cookie： request.COOKIES[‘key’] request.get_signed_cookie(key, default=RAISE_ERROR, salt=’’, max_age=None) 参数： default: 默认值 salt: 加密盐 max_age: 后台控制过期时间 2、设置Cookie：12345678910111213rep = HttpResponse(...) 或 rep ＝ render(request, ...)rep.set_cookie(key,value,...)rep.set_signed_cookie(key,value,salt=&apos;加密盐&apos;,...)​ 参数：​ key, 键​ value=&apos;&apos;, 值​ max_age=None, 超时时间​ expires=None, 超时时间(IE requires expires, so set it if hasn&apos;t been already.)​ path=&apos;/&apos;, Cookie生效的路径，/ 表示根路径，特殊的：跟路径的cookie可以被任何url的页面访问​ domain=None, Cookie生效的域名​ secure=False, https传输​ httponly=False 只能http协议传输，无法被JavaScript获取（不是绝对，底层抓包可以获取到也可以被覆盖） 由于cookie保存在客户端的电脑上，所以，JavaScript和jquery也可以操作cookie。 12&lt;script src=&apos;/static/js/jquery.cookie.js&apos;&gt;&lt;/script&gt;$.cookie(&quot;list_pager_num&quot;, 30,&#123; path: &apos;/&apos; &#125;); SessionDjango中默认支持Session，其内部提供了5种类型的Session供开发者使用： 数据库（默认）缓存文件缓存+数据库加密cookie 1、数据库Session12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Django默认支持Session，并且默认是将Session数据存储在数据库中，即：django_session 表中。a. 配置 settings.py SESSION_ENGINE = &apos;django.contrib.sessions.backends.db&apos; # 引擎（默认） SESSION_COOKIE_NAME ＝ &quot;sessionid&quot; # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串（默认） SESSION_COOKIE_PATH ＝ &quot;/&quot; # Session的cookie保存的路径（默认） SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名（默认） SESSION_COOKIE_SECURE = False # 是否Https传输cookie（默认） SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输（默认） SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周）（默认） SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期（默认） SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存（默认） b. 使用 def index(request): # 获取、设置、删除Session中数据 request.session[&apos;k1&apos;] request.session.get(&apos;k1&apos;,None) request.session[&apos;k1&apos;] = 123 request.session.setdefault(&apos;k1&apos;,123) # 存在则不设置 del request.session[&apos;k1&apos;] # 所有 键、值、键值对 request.session.keys() request.session.values() request.session.items() request.session.iterkeys() request.session.itervalues() request.session.iteritems() # 用户session的随机字符串 request.session.session_key # 将所有Session失效日期小于当前日期的数据删除 request.session.clear_expired() # 检查 用户session的随机字符串 在数据库中是否 request.session.exists(&quot;session_key&quot;) # 删除当前用户的所有Session数据 request.session.delete(&quot;session_key&quot;) 2、缓存Session1234567891011121314151617181920a. 配置 settings.py SESSION_ENGINE = &apos;django.contrib.sessions.backends.cache&apos; # 引擎 SESSION_CACHE_ALIAS = &apos;default&apos; # 使用的缓存别名（默认内存缓存，也可以是memcache），此处别名依赖缓存的设置 SESSION_COOKIE_NAME ＝ &quot;sessionid&quot; # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串 SESSION_COOKIE_PATH ＝ &quot;/&quot; # Session的cookie保存的路径 SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名 SESSION_COOKIE_SECURE = False # 是否Https传输cookie SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输 SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周） SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期 SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存b. 使用 同上 3、文件Session123456789101112131415161718a. 配置 settings.py SESSION_ENGINE = &apos;django.contrib.sessions.backends.file&apos; # 引擎 SESSION_FILE_PATH = None # 缓存文件路径，如果为None，则使用tempfile模块获取一个临时地址tempfile.gettempdir() # 如：/var/folders/d3/j9tj0gz93dg06bmwxmhh6_xm0000gn/T SESSION_COOKIE_NAME ＝ &quot;sessionid&quot; # Session的cookie保存在浏览器上时的key，即：sessionid＝随机字符串 SESSION_COOKIE_PATH ＝ &quot;/&quot; # Session的cookie保存的路径 SESSION_COOKIE_DOMAIN = None # Session的cookie保存的域名 SESSION_COOKIE_SECURE = False # 是否Https传输cookie SESSION_COOKIE_HTTPONLY = True # 是否Session的cookie只支持http传输 SESSION_COOKIE_AGE = 1209600 # Session的cookie失效日期（2周） SESSION_EXPIRE_AT_BROWSER_CLOSE = False # 是否关闭浏览器使得Session过期 SESSION_SAVE_EVERY_REQUEST = False # 是否每次请求都保存Session，默认修改之后才保存b. 使用 同上 4、缓存+数据库Session123456789数据库用于做持久化，缓存用于提高效率a. 配置 settings.py SESSION_ENGINE = &apos;django.contrib.sessions.backends.cached_db&apos; # 引擎b. 使用 同上 5、加密cookie Session1234567a. 配置 settings.py SESSION_ENGINE = &apos;django.contrib.sessions.backends.signed_cookies&apos; # 引擎b. 使用 同上 示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from django.shortcuts import render,redirect# Create your views here.import datetimedef login(request): print(&quot;COOKIES&quot;,request.COOKIES) #打印cookies 一个字典，里面多个键值对 print(&quot;SESSION&quot;,request.session) #session为服务器对应客户信息的键 if request.method==&quot;POST&quot;: name=request.POST.get(&quot;user&quot;) pwd=request.POST.get(&quot;pwd&quot;) if name==&quot;yuan&quot; and pwd==&quot;123&quot;: # ret=redirect(&quot;/index/&quot;) # 给对象ret设置cookie 安全性较差 ,设定有效时间max_age，expires， # ret.set_cookie(&quot;username&quot;,&#123;&quot;11&quot;:&quot;22&quot;&#125;,max_age=10,expires=datetime.datetime.utcnow()+datetime.timedelta(days=3)) # return ret # COOKIE SESSION一起使用 # session 以字典存放在服务器端，发给客户端的是数据对应的键， request.session[&quot;is_login&quot;]=True # 在session中增加键值对 request.session[&quot;user&quot;]=name return redirect(&quot;/index/&quot;) return render(request,&quot;login.html&quot;)def index(request): if request.COOKIES.get(&quot;username&quot;,None): # 取不到设置默认值为None name = request.COOKIES.get(&quot;username&quot;,None) return render(request, &quot;index.html&quot;, locals()) # session验证 存在数据库中，所以要先makemigrations生成数据库 if request.session.get(&quot;is_login&quot;,None): name=request.session.get(&quot;user&quot;,None) return render(request,&quot;index.html&quot;,locals()) else: return redirect(&quot;/login/&quot;)##session获取request.session.get(&quot;user&quot;,None)# 设置request.session[&quot;user&quot;]=name# 删除del request.session.get(&quot;user&quot;)","categories":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/tags/django/"},{"name":"cookie","slug":"cookie","permalink":"http://www.baidu.com/tags/cookie/"},{"name":"session","slug":"session","permalink":"http://www.baidu.com/tags/session/"}],"author":"yuanfeng"},{"title":"LVS","slug":"LVS","date":"2019-04-18T15:22:43.000Z","updated":"2019-05-05T07:30:06.599Z","comments":true,"path":"2019/04/18/LVS/","link":"","permalink":"http://www.baidu.com/2019/04/18/LVS/","excerpt":"","text":"LVSLVS(linux virtual server)即linux虚拟服务器，是一个虚拟的服务器集群系统。 使用集群技术和Linux操作系统实现一个高性能,高可用的服务器,很好的可伸缩性(scalability),很好的可靠性(reliability),很好的可管理性(manageability). contos7: grep -i ipvs /boot/config-3.10.0-693.e17.x86_64 grep -i ipvs -C 10 /boot/config-3.10.0-693.e17.x86_64 yum install ipvsadm rpm -ql ipvsadm curl命令 lvs服务器:需要两块网卡 启用Ipforward： echo net.ipv4.ip_forward=1 &gt;&gt; /etc/sysctl.conf sysctl -p sysctl -a | grep ip_forward iptables -vnl client：需要桥接 RS1：设置网关 yum install httpd echo RS1 &gt; /var/www/html/index.html RS2；设置网关 yum install httpd echo RS2 &gt; /var/www/html/index.html LVS： 定义ipvs规则:NAt模式 yum install ipvsadm ipvsadm -A -t 172.20.0.200:80 -s rr ipvsadm -Ln ipvsadm -a -t 172.20.0.200:80 -r 192.168.80.17 -m ipvsadm -a -t 172.20.0.200:80 -r 192.168.80.27 -m ipvsadm -Ln 并发4百万 apache 1万 集群Cluster概念 系统扩展方式： scale up: 向上扩展，增强 scale out: 向外扩展，增加设备，调度分配问题， cluster Cluster: 集群，未解决某个特定问题将多台计算机组合起来形成的单个系统 Linux Cluster类型： LB：load blancing, 负载均衡 HA：high availiablity, 高可用， spof(single point of failure) MTBF: Mean Time Between Failure 平均无故障时间 MTTR: Mean Time To REStoration (repair) 平均恢复前时间（故障时间） A=MTBF/(MTBF+MTTR) (0,1): 99%,99.5%, 99.9%, 99.99%, 99.999% HPC: high-performance computing . 高性能 www.top500.org 分布式系统：分布式存储： 云盘 分布式计算： hadoop, spark Cluster分类 LB Cluster的实现 硬件：F5 big-ip citrix netscaler A10 A10 软件:lvs: linux virtual server nginx: 支持七层调度 haproxy: 支持七层调度 ats: apache trafficserver perlbal: perl编写 pound 基于工作的协议层划分： 传输层（通用）：DPORT LVS： nginx：stream haproxy: mode tcp 应用层（专用）：针对特定协议，自定义的请求模型分类 proxy server： http:nginx, httpdm haproxy(mode http),... fastcgi: nginx, httpd, ... mysql: mysql-proxy,... 会话保持：负载均衡 （1）session sticky: 同一用户调度固定服务器 source ip: lvs sh算法（对某一特定服务而言） cookie （2）session replication: 每台服务器拥有全部session session multicast cluster （3）session server: 专门的session服务器 memcached， redis HA集群实现方案 keepalived: vrrp协议 ais：应用接口规范heartbeat cman + rgmanager(RHCS) coresync_pacemaker LVS介绍LVS介绍 LVS: linux virtual server, 负载调度器，集成内核 官网：http://www.linuxvirtualserver.org/ VS：virtual server，负责调度 RS：real server,负责真正提供服务 L4：四层路由器或交换机 工作原理：vs根据请求报文的目标ip和目标协议及端口将其调度转发至某RS，根据调度算法来挑选RS iptables/netfilter: iptables:用户空间的管理工具 netfilter:内核空间上的框架 流入：PREROUTING–&gt;INPUT 流出：OUTPUT–&gt; POSTROUTING 转发：PREROUTING–&gt;FORWARD–&gt;POSTROUTING DNAT：目标地址转换；PREROUTING LVS概念 lvs集群类型中的术语： VS：virtual server, director server(DS) dispatcher(调度器)，load balancer RS:real server(lvs), upstream server(nginx) backend server(haproxy) CIP:client ip VIP:virtual serve ip VS外网的ip DIP:director ip VS内网Ip RIP:real server ip 访问流程：CIPVIP==DIPRIP LVS集群的类型 lvs: ipvsadm/ipvs ipvsadm: 用户空间的命令行工具，规则管理器 ipvs: 工作于内核空间netfilter的INPUT钩子上的框架 lvs集群的类型： lvs-nat: 修改请求报文的目标IP，多目标IP的DNAT lvs-dr: 操纵封装新的MAC地址 lvs-tun: 在原请求IP报文之外新加一个IP首部 lvs-fullnat: 修改请求报文的源和目标IP lvs-nat模式 lvs-nat: 本质是多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发 (1)RIP和DIP应在同一个IP网络，且应使用私网地址，RS的网关要指向DIP (2)请求报文和响应报文都必须经由Director转发，Director易于成为系统瓶颈 (3)支持端口映射，可修改请求报文的目标PORT (4)VS必须是linux系统，RS可以是任意OS系统 lvs-fullnat模式 lvs-fullnat: 通过同时修改请求报文的源IP地址和目标IP地址进行转发CIP--&gt;DIP VIP--&gt;RIP (1)VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此。RIP的网关一般不会指向DIP (2)RS收到的请求报文源地址是DIP，因此，只需响应给DIP；但Director还要将其发往Client (3)请求和响应报文都经由Director (4)支持端口映射 注意：此类型kernel默认不支持 LVS工作模式总结 VS/NAT VS/TUN VS/DR server any tunneling non-arp device server network private LAN/WAN LAN server number low(10~20) high(100) high(100) server gateway load balancer own router own router lvs-nat与lvs-fullnat:请求和响应报文都经由director lvs-nat:RIP的网关要指向DIP lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信 lvs-dr与lvs-tun:请求报文要经由director，但相应报文有RS直接发往client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发 lvs-tun: 通过在院IP报文外封装新IP头实现转发，支持远距离通信 ipvs scheduler ipvs scheduler: 根据其调度时是否考虑各RS当前的负载状态 两种：静态方法和动态方法 静态方法：仅根据算法本身进行调度 1. RR: roundrobin,轮询 2. WRR: weighted RR,加权轮询 3. SH: source hashing,实现session sticky，源IP地址hash；将来自同一个IP地址的请求，始终发往第一次挑中的RS，从而实现会话绑定 4. DH: destination hashing, 目标地址哈希，将发往同一个目标地址的骑牛始终发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡；如：宽带运行商 动态方法： 主要根据每个RS当前的负载状态及调度算法进行调度overhead=value较小的RS将被调度 LC: least connections 适用于长连接应用 overhead=activeconns*256+inactiveconns WLC: weighted LC,默认调度方法 overhead=(acticeconns*256+inactiveconns)/weight SED: shortest expection delay,初始连接高权重优先 overhead=(activeconns+1)*256/weight NQ: never queue, 第一轮均匀分配，后续sed LBLC: locality-based LC，动态的DH算法，使用场景：根据负载状态实现正向代理 LBLCR: LBLC with replication, 带复制功能的LBLC，解决LBLC负载不均衡问题，从负载重的复制到负载轻的RS ipvsadm命令 ipvsadm 命令： 核心功能： 集群服务管理：增，删，改 集群服务的RS管理：增，删，改 查看 ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] [-M netmask] [–pe persistence_engine] [-b sched-flags] ipvsadm -D -t|u|f service-address 删除 ipvsadm -C 清空 ipvsadm -R 重载 ipvsadm -S [-n] 保存 ipvsadm -a|e -t|u|f service-address -r server-address [options] ipvsadm -d -t|u|f service-address -r server-address ipvsadm -L|l [options] ipvsadm -Z [-t|U|f service-address] 管理集群上的RS：增，删，改 增、改：ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 删：ipvsadm -d -t|u|f service-address -r server-address server-addres: rip[:port] 如省略port，不作端口映射 选项： lvs类型:-g: gateway, dr类型，默认 -i: ipip，tun类型 -m: masquerade, nat类型 -w weight: 权重 参考http://blog.sina.com.cn/s/blog_6786545e0102vjvq.html","categories":[{"name":"lvs","slug":"lvs","permalink":"http://www.baidu.com/categories/lvs/"}],"tags":[{"name":"lvs","slug":"lvs","permalink":"http://www.baidu.com/tags/lvs/"}],"author":"yuanfeng"},{"title":"django集成celery","slug":"django_celery","date":"2019-04-17T19:22:43.000Z","updated":"2019-05-05T12:39:42.276Z","comments":true,"path":"2019/04/18/django_celery/","link":"","permalink":"http://www.baidu.com/2019/04/18/django_celery/","excerpt":"","text":"Django集成Celery到项目将celery集成到Django项目中，实现异步任务处理和定时任务处理 Celery工作流程 celery流程图 Celery的架构由三部分组成，消息中间件（message broker），任务执行单元（worker）和任务执行结果存储（task result store）组成。 消息中间件 Celery本身不提供消息服务，但是可以方便的和第三方提供的消息中间件集成。包括，RabbitMQ, Redis, MongoDB (experimental), Amazon SQS (experimental),CouchDB (experimental), SQLAlchemy (experimental),Django ORM (experimental), IronMQ 任务执行单元 Worker是Celery提供的任务执行的单元，worker并发的运行在分布式的系统节点中。 任务结果存储 Task result store用来存储Worker执行的任务的结果，Celery支持以不同方式存储任务的结果，包括AMQP, Redis，memcached, MongoDB，SQLAlchemy, Django ORM，Apache Cassandra, IronCache 1.Celery安装与配置在虚拟环境中安装: pip install django-celery==3.2.2 pip install django-redis pip install flower # celery 的web管理平台(异步任务可视化) 查看集成到Django中的celery版本， pip freeze celery==3.1.26.post2 django-celery==3.2.2 flower==0.9.2 启动redis服务， 端口假设为6379 发现pip安装比较慢的情况 pip install pillow -i https://pypi.douban.com/simple 2.Django中配置（1）在主工程的配置文件settings.py 中应用注册表INSTALLED_APPS中加入 djcelery12345678910111213INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;art&apos;, &apos;xadmin&apos;, &apos;crispy_forms&apos;, &apos;DjangoUeditor&apos;, &apos;djcelery&apos;, #加入djcelery] (2) 在settings.py 中加入celery配置信息12345678910111213141516171819202122# celery 配置信息 startimport djcelerydjcelery.setup_loader()BROKER_URL = &apos;redis://127.0.0.1:6379/1&apos;CELERY_IMPORTS = (&apos;art.tasks&apos;)CELERY_TIMEZONE = &apos;Asia/Shanghai&apos;CELERYBEAT_SCHEDULER = &apos;djcelery.schedulers.DatabaseScheduler&apos; from celery.schedules import crontabfrom celery.schedules import timedeltaCELERYBEAT_SCHEDULE = &#123; #定时器策略 #定时任务一： 每隔30s运行一次 u&apos;测试定时器1&apos;: &#123; &quot;task&quot;: &quot;art.tasks.tsend_email&quot;, #&quot;schedule&quot;: crontab(minute=&apos;*/2&apos;), # or &apos;schedule&apos;: timedelta(seconds=3), &quot;schedule&quot;:timedelta(seconds=30), &quot;args&quot;: (), &#125;,&#125;# celery 配置信息 end ​ 当djcelery.setup_loader()运行时，Celery便会去查看INSTALLD_APPS下包含的所有app目录中的tasks.py文件，找到标记为task的方法，将它们注册为celery task ​ BROKER_URL：broker是代理人，它负责分发任务给worker去执行。我使用的是Redis作为broker ​ 没有设置 CELERY_RESULT_BACKEND，默认没有配置，此时Django会使用默认的数据库(也是你指定的orm数据库)。 CELERY_IMPORTS：是导入目标任务文件 CELERYBEAT_SCHEDULER：使用了django-celery默认的数据库调度模型,任务执行周期都被存在默认指定的orm数据库中． CELERYBEAT_SCHEDULE：设置定时的时间配置， 可以精确到秒，分钟，小时，天，周等。 （3）创建应用实例​在主工程目录添加celery.py， 添加自动检索django工程tasks任务 ​vim artproject/celery.py 1234567891011121314151617#!/usr/bin/env python # encoding: utf-8 #目的是拒绝隐士引入，celery.py和celery冲突。from __future__ import absolute_import,unicode_literals import osfrom celery import Celeryfrom django.conf import settings# 设置环境变量os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;artproject.settings&quot;)#创建celery应用app = Celery(&apos;art_project&apos;)app.config_from_object(&apos;django.conf:settings&apos;)#如果在工程的应用中创建了tasks.py模块，那么Celery应用就会自动去检索创建的任务。比如你添加了一个任#务，在django中会实时地检索出来。app.autodiscover_tasks(lambda :settings.INSTALLED_APPS) (4) 创建任务 tasks每个任务本质上就是一个函数，在tasks.py中，写入你想要执行的函数即可。 在应用art中添加我们需要提供的异步服务和定时服务 vim art/tasks.py 1234567891011121314151617181920212223#!/usr/bin/env python # encoding: utf-8 from __future__ import absolute_importimport timefrom django.core.mail import send_mailfrom celery.utils.log import get_task_loggerfrom artproject.celery import appfrom art.utils.send_mail import pack_html, send_email@app.taskdef tsend_email(): url = &quot;http://1000phone.com&quot; receiver = &apos;diyuhuan@1000phone.com&apos; content = pack_html(receiver, url) # content = &apos;this is email content.&apos; send_email(receiver, content) print(&apos;send email ok!&apos;)@app.taskdef add(x, y): return x+y 上述我们把异步处理任务add和定时器任务tsend_email都放在了tasks.py 中 （5）迁移生成celery需要的数据表python manage.py migrate 此时数据库表结构多出了几个 12345678celery_taskmeta || celery_tasksetmeta || djcelery_crontabschedule || djcelery_intervalschedule || djcelery_periodictask || djcelery_periodictasks || djcelery_taskstate || djcelery_workerstate 3.启动服务，测试我们可以采用 python manage.py help 发现多出了 celery 相关选项。 （1）启动django celery 服务启动服务： python manage.py celery worker --loglevel=info 此时异步处理和定时处理服务都已经启动了 （2）web端接口触发异步任务处理我们在web端加入一个入口，触发异步任务处理add函数 在应用art的urls.py 中加入如下对应关系 123from art.views import add_handlerurl(r&apos;^add&apos;, add_handler), art/views.py 中加入处理逻辑 1234567def add_handler(request): x = request.GET.get(&apos;x&apos;, &apos;1&apos;) y = request.GET.get(&apos;y&apos;, &apos;1&apos;) from .tasks import add add.delay(int(x), int(y)) res = &#123;&apos;code&apos;:200, &apos;message&apos;:&apos;ok&apos;, &apos;data&apos;:[&#123;&apos;x&apos;:x, &apos;y&apos;:y&#125;]&#125; return HttpResponse(json.dumps(res)) 启动web服务，通过url传入的参数，通过handler的add.delay(x, y)计算并存入mysql http://127.0.0.1:8000/art/add?x=188&amp;y=22 (4)测试定时器，发送邮件在终端输入 python manage.py celerybeat -l info 会自动触发每隔30s执行一次tsend_email定时器函数，发送邮件： 123456789CELERYBEAT_SCHEDULE = &#123; #定时器策略 #定时任务一： 每隔30s运行一次 u&apos;测试定时器1&apos;: &#123; &quot;task&quot;: &quot;art.tasks.tsend_email&quot;, #&quot;schedule&quot;: crontab(minute=&apos;*/2&apos;), # or &apos;schedule&apos;: timedelta(seconds=3), &quot;schedule&quot;:timedelta(seconds=30), &quot;args&quot;: (), &#125;,&#125; 具体发送邮件服务程序见下面的第4节 4.邮件发送服务项目中经常会有定时发送邮件的情形，比如发送数据报告，发送异常服务报告等。 可以编辑文件 art/utils/send_mail.py, 内容编辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/usr/bin/env python#-*- coding:utf-8 -*-#written by diyuhuan#发送邮件(wd_email_check123账号用于内部测试使用，不要用于其他用途)import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.image import MIMEImage from email.header import Headerimport timesender = &apos;wd_email_check123@163.com&apos; subject = u&apos;api开放平台邮箱验证&apos;smtpserver = &apos;smtp.163.com&apos;username = &apos;wd_email_check123&apos;password = &apos;wandacheck1234&apos;mail_postfix=&quot;163.com&quot;def send_email(receiver, content): try: me = username+&quot;&lt;&quot;+username+&quot;@&quot;+mail_postfix+&quot;&gt;&quot; msg = MIMEText(content, &apos;html&apos;, &apos;utf-8&apos;) msg[&apos;Subject&apos;] = subject msg[&apos;From&apos;] = sender msg[&apos;To&apos;] = receiver smtp = smtplib.SMTP() smtp.connect(smtpserver) smtp.login(username, password) smtp.sendmail(sender, receiver, msg.as_string()) smtp.quit() return True except Exception as e: print(&apos;send_email has error with : &apos; + str(e)) return Falsedef pack_html(receiver, url): html_content = u&quot;&lt;html&gt;&lt;div&gt;尊敬的用户&lt;font color=&apos;#0066FF&apos;&gt;%s&lt;/font&gt; 您好！&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;感谢您关注我们的平台 ，我们将为您提供最贴心的服务，祝您购物愉快。&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;点击以下链接，即可完成邮箱安全验证：&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;&lt;a href=&apos;%s&apos;&gt;%s&lt;/a&gt;&lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;为保障您的帐号安全，请在24小时内点击该链接; &lt;/div&gt;&lt;br&gt;&quot; \\ &quot;&lt;div&gt;若您没有申请过验证邮箱 ，请您忽略此邮件，由此给您带来的不便请谅解。&lt;/div&gt;&quot; \\ &quot;&lt;/html&gt;&quot; % (receiver, url, url) html_content = html_content return html_contentif __name__ == &quot;__main__&quot;: url = &quot;http://1000phone.com&quot; receiver = &apos;diyuhuan@1000phone.com&apos; #content = pack_html(receiver, url) content = &apos;this is email content. at %s.&apos;%int(time.time()) send_email(receiver, content) 至此，在celery ui界面可以看到两类，定时器处理和异步处理。 5.启动flower服务python manager celery flower","categories":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/tags/django/"},{"name":"celery","slug":"celery","permalink":"http://www.baidu.com/tags/celery/"}],"author":"yuanfeng"},{"title":"django中的日志处理","slug":"django_logging","date":"2019-04-17T19:22:43.000Z","updated":"2019-05-05T11:56:10.006Z","comments":true,"path":"2019/04/18/django_logging/","link":"","permalink":"http://www.baidu.com/2019/04/18/django_logging/","excerpt":"","text":"1 Django中加入日志功能Django 中使用python的 logging 模块记录log，在 Django 中使用 Django 提供的配制方法。就是在 settings 中通过变量 LOGGING，LOGGING 是一个字典，典型的配置如下： ​logging模块为应用程序提供了灵活的手段记录事件、错误、警告和调试信息。对这些信息可以进行收集、筛选、写入文件、发送给系统日志等操作，甚至还可以通过网络发送给远程计算机。 （1）日志记录级别​logging模块的重点在于生成和处理日志消息。每条消息由一些文本和指示其严重性的相关级别组成。级别包含符号名称和数字值。 级别 值 描述 CRITICAL/FATAL 50 关键错误/消息 ERROR 40 错误 WARNING 30 警告消息 INFO 20 通知消息 DEBUG 10 调试 NOTSET 0 无级别 （2）记录器（日志对象-logging.getLogger()）-默认的root记录器​记录器负责管理日志消息的默认行为，包括日志记录级别、输出目标位置、消息格式以及其它基本细节。 如下是处理器Handler关键的参数： 关键字参数 描述 filename 将日志消息附加到指定文件名的文件 filemode 指定用于打开文件模式 format 用于生成日志消息的格式字符串 datefmt 用于输出日期和时间的格式字符串 level 设置记录器的级别 stream 提供打开的文件，用于把日志消息发送到文件。 （3）format 日志消息格式​e.g. ‘%(asctime)s %(module)s %(level)s %(lineno)d’ 格式 描述 %(name)s 记录器的名称, 默认为root %(levelno)s 数字形式的日志记录级别 %(levelname)s 日志记录级别的文本名称 %(filename)s 执行日志记录调用的源文件的文件名称 %(pathname)s 执行日志记录调用的源文件的路径名称 %(funcName)s 执行日志记录调用的函数名称 %(module)s 执行日志记录调用的模块名称 %(lineno)s 执行日志记录调用的行号 %(created)s 执行日志记录的时间 %(asctime)s 日期和时间 %(msecs)s 毫秒部分 %(thread)d 线程ID %(threadName)s 线程名称 %(process)d 进程ID %(message)s 记录的消息 （4）内置处理器​ logging模块提供了一些处理器，可以通过各种方式处理日志消息。使用addHandler()方法将这些处理器添加给Logger对象。另外还可以为每个处理器配置它自己的筛选和级别。 ​ handlers.DatagramHandler(host，port):发送日志消息给位于制定host和port上的UDP服务器。 ​ * handlers.FileHandler(filename): 将日志消息写入文件filename。 ​ handlers.HTTPHandler(host, url):使用HTTP的GET或POST方法将日志消息上传到一台HTTP 服务器。 ​ * handlers.RotatingFileHandler(filename):将日志消息写入文件filename。如果文件的大小超出maxBytes制定的值，那么它将被备份为filename1。 ​ 由于内置处理器还有很多，如果想更深入了解。可以查看官方手册。 （5）python的日志简单地用法1234567891011# 设置日志等级logging.getLogger().setLevel(logging.INFO)formatter = '%(asctime)s: %(filename)s/%(funcName)s at %(lineno)s-&gt;%(message)s'# 配置日志的信息，filename 要指定日志输出的文件名logging.basicConfig(format=formatter, datefmt='%Y-%m-%d %H:%M:%S', filename='art.log', filemode='a')logging.warning('--当前页面要被缓存5秒---') 2 Django中使用日志在Django的配置文件settings.py 中加入如下LOGGING配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566## Django Logging BEGIN#LOGGING_DIR 日志文件存放目录LOGGING_DIR = &quot;/home/xxt/logs&quot;if not os.path.exists(LOGGING_DIR): os.mkdir(LOGGING_DIR)import loggingLOGGING = &#123; &apos;version&apos;: 1, &apos;disable_existing_loggers&apos;: False, &apos;formatters&apos;: &#123; &apos;standard&apos;: &#123; &apos;format&apos;: &apos;[%(levelname)s][%(asctime)s][%(filename)s][%(funcName)s][%(lineno)d] &gt; %(message)s&apos; &#125;, &apos;simple&apos;: &#123; &apos;format&apos;: &apos;[%(levelname)s]&gt; %(message)s&apos;, &apos;datefmt&apos;: &apos;%Y-%m-%d %H:%M:%S&apos; &#125;, &#125;, &apos;filters&apos;: &#123; &apos;require_debug_true&apos;: &#123; &apos;()&apos;: &apos;django.utils.log.RequireDebugTrue&apos;, &#125;, &#125;, &apos;handlers&apos;: &#123; &apos;console&apos;: &#123; &apos;level&apos;: &apos;DEBUG&apos;, &apos;filters&apos;: [&apos;require_debug_true&apos;], &apos;class&apos;: &apos;logging.StreamHandler&apos;, &apos;formatter&apos;: &apos;simple&apos; &#125;, &apos;file_handler&apos;: &#123; &apos;level&apos;: &apos;INFO&apos;, &apos;class&apos;: &apos;logging.handlers.TimedRotatingFileHandler&apos;, &apos;filename&apos;: &apos;%s/django.log&apos; % LOGGING_DIR, &apos;formatter&apos;:&apos;standard&apos;, &apos;encoding&apos;: &apos;utf-8&apos; &#125;, # 用于文件输出 &apos;mail_admins&apos;: &#123; &apos;level&apos;: &apos;ERROR&apos;, &apos;class&apos;: &apos;django.utils.log.AdminEmailHandler&apos;, &apos;formatter&apos;:&apos;standard&apos; &#125;, &#125;, &apos;loggers&apos;: &#123; &apos;mdjango&apos;: &#123; &apos;handlers&apos;: [&apos;console&apos;,&apos;file_handler&apos;], &apos;level&apos;:&apos;DEBUG&apos;, &apos;propagate&apos;: True, &#125;, &apos;django.request&apos;: &#123; &apos;handlers&apos;: [&apos;mail_admins&apos;], &apos;level&apos;: &apos;ERROR&apos;, &apos;propagate&apos;: False, &#125;, &#125;&#125; logger = logging.getLogger(&quot;mdjango&quot;)## Django Logging END 最新日志内容存入： django.log 前一天：django.log.2018-05-29 前前一天：django.log.2018-05-28 django.log.2018-05-22 在具体的业务逻辑代码中加入日志记录 123from Project.settings import loggerlogger.info(&quot;IndexHandler request Handler begin&quot;)logger.debug(&apos;query total:&apos; + str(total)) 观察日志打印情况。 一般python使用日志功能（非django框架） 12345678910111213import loggingdef logging_init(): app_name = &quot;AppName&quot; log_file_name = &quot;myapp_test.log&quot; logger = logging.getLogger(app_name) format_str = &quot;[%(asctime)s][%(levelname)s]&gt; %(message)s&quot; formatter = logging.Formatter(format_str) file_handler = logging.FileHandler(log_file_name) file_handler.setFormatter(formatter) logger.addHandler(file_handler) logger.setLevel(logging.INFO) return logger 单例模式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import loggingclass Singleton(object): _instance = None def __new__(cls, *args, **kwargs): if not cls._instance: cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls._instance app_name = &quot;appName&quot;log_file = &quot;test.log&quot;class SingletonLogger(Singleton): def __init__(self): super(SingletonLogger, self).__init__() self.logger = logging.getLogger(app_name) format_str = &quot;[%(asctime)s][%(levelname)s]&gt; %(message)s&quot; formatter = logging.Formatter(format_str) file_handler = logging.FileHandler(log_file) file_handler.setFormatter(formatter) self.logger.addHandler(file_handler) self.logger.setLevel(logging.INFO) def debug(self, data): self.logger.debug(data) def info(self, data): self.logger.info(data) def warning(self, data): self.logger.warning(data) def error(self, data): self.logger.error(data)def test_log(): logger = SingletonLogger() #output the log msg logger.debug(&quot;this is the debug message&quot;) logger.info(&quot;this is the info message&quot;) logger.warning(&quot;this is the warning message&quot;) logger.error(&quot;this is the error message&quot;)","categories":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://www.baidu.com/tags/django/"},{"name":"log","slug":"log","permalink":"http://www.baidu.com/tags/log/"}],"author":"yuanfeng"},{"title":"plan","slug":"plan","date":"2019-04-05T09:36:34.000Z","updated":"2019-05-05T14:02:36.934Z","comments":true,"path":"2019/04/05/plan/","link":"","permalink":"http://www.baidu.com/2019/04/05/plan/","excerpt":"","text":"autoMysql / Mongodb / RedisTomact NginxKubernetes / Dockerpython shellAnsible/ Puppet / SaltStack / FabricZabbix/ Nagios / Cacti / Grafana / Prometheus / ELK /Kafka jenkins / gitlab / Lvs / HaproxyLAMP / LNMP/ DAS/SNA/NAS/","categories":[{"name":"plan other","slug":"plan-other","permalink":"http://www.baidu.com/categories/plan-other/"}],"tags":[{"name":"plan","slug":"plan","permalink":"http://www.baidu.com/tags/plan/"}],"author":"yuanfeng"},{"title":"hexo","slug":"hexo","date":"2019-04-05T09:36:34.000Z","updated":"2019-05-21T00:30:37.041Z","comments":true,"path":"2019/04/05/hexo/","link":"","permalink":"http://www.baidu.com/2019/04/05/hexo/","excerpt":"","text":"基本操作 文件/文件夹 说明 _config.yml 配置文件 public 生成的静态文件，这个目录最终会发布到服务器 scaffolds 一些通用的markdown模板 source 编写的markdown文件，_drafts草稿文件，_posts发布的文章 themes 博客的模板 常用命令 hexo new &quot;postName&quot; hexo new page &quot;pageName&quot; hexo server npm install hexo-cli -g hexo init blog cd blog npm install hexo server 创建一篇新的文章 hexo new [layout] &lt;title&gt; hexo有三种默认的布局：post,page,draft他们分别对应的路径如下|布局|路径||—|—||post|source/_posts||page|source||draft|source/_drafts| 提交到github安装git插件 npm install hexo-deployer-git --save git的配置，修改_config.yml文件 deploy: type: git repository: git@github.com:love-fengyuan/love-fengyuan.github.io.git branch: master 将代码push到github： hexo deploy 常见问题执行deploy命令了，但是代码未上传？ 先执行hexo generate命令，生成静态文件了，再执行hexo deploy上传，上传是只会上传public中生成的文件。 修改了模板，但是没有生效？ 修改了模板没有生效，建议先“hexo clean”，然后在“hexo generate”，只执行hexo generate，可能模板后者静态文件不会替换。 第二篇博客 hexo new title 修改显示路径，使用start路径来编辑它（如果是\\斜杠需换成/斜杠） hexo generate hexo deploy 查看博客 插入图片视频插入图片 ![k8sss](test/k8s_jg.png) 插入视频 &lt;video href=&apos;test/roam_1.mp4&apos; type=&apos;video/mp4&apos; controls=&apos;controls&apos; width=&apos;100%&apos; height=&apos;100%&apos;&gt;love&lt;/video&gt; {% raw %} {% endraw%} 参考官网：https://hexo.io/zh-cn/ https://www.jianshu.com/p/da491b249aee https://www.jianshu.com/p/a7cc54797ecc","categories":[{"name":"hexo","slug":"hexo","permalink":"http://www.baidu.com/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.baidu.com/tags/hexo/"}],"author":"yuanfeng"},{"title":"ansible","slug":"ansible","date":"2019-03-10T15:06:52.000Z","updated":"2019-05-05T07:25:07.423Z","comments":true,"path":"2019/03/10/ansible/","link":"","permalink":"http://www.baidu.com/2019/03/10/ansible/","excerpt":"","text":"AnsibleAnsible 基础 ANSIBLE_CONFIG 环境变量，可以定义配置文件的位置 ./ansible.cfg 存在于当前工作目录 ~/.ansible.cfg 存在于当前用户家目录 /etc/ansible/ansible.cfg 默认目录 Ansible命令主机要求：windows除外 配置语言： yaml，json只有server role:ansible 可以重复使用的 Ansible: https://github.com/ansible/ansible 从release下载安装包 需要pip安装包的依赖 log： https://www.cnblogs.com/xielisen/p/6817807.html 查看文件个数：ls -l | grep ‘^-‘ | wc -l ##################################马哥 Ansible 文件传输命令执行：应用部署，配置管理，任务流编排 企业应用场景：开发，测试，发布，生产，灰度环境（基于主机，用户，地区） vie0 修改主机ip ansible -m pingm:模块ansible 127.0.0.1 -m ping 在 /etc/ansible/hosts中配置主机清单 测试网络通讯; ansible 192.168.1.101 -m ping -k 输入口令（密码）k: 密码认证建议基于key验证 etc/ssh/sshd_config ansible all -m ping all: 代表主机清单的所有主机 ansible.cfgansible.cfg forks=5 并发执行5 ansible-doc:显示模块命令 ansible websevers –list-hosts ansible all –list-host ansible debserver -m ping -u wang -k 以wang的身份去连接 ansible debserver -m command -a ‘ls /root’ -u wang -k -b -K以wang身份连接，切换到root用户权限，默认为root -K root口令 usermod -a -G wheel wang 将wang加入到组 K的口令;sudo中：取消下面一行的注释：%wheel ALL=(ALL) NOPASSWD:ALL 基于key验证 ssh-keygen ssh-copy-id 192.168.80.101 ssh-copy-id 192.168.80.102 ....... &amp; linux中表示后台执行 ansible all -m command -a “sleep 10”休眠10s command: ansible all -a ‘ls /data’ ansible all -a ‘df -h’ ansible-doc command creates 存在不执行 ansible all -a ‘removes=/etc/fs cat /etc/fstab’ removes 不存在不执行 ansible all -a ‘creates=/etc/fs cat /etc/fstab’ chdir 切换文件夹 ansible all -a ‘chdir=/root ls’ ansible 192.168.80.101 -a ‘/data/test.sh’ 执行该主机上/data/test.sh 注： 注意规范 #！/bin/bash 创建账号： ansible all -a &apos;useradd test1&apos; 查询： ansible all -a &apos;getent passwd test1&apos; command 命令对管道，重定向,变量 特殊符号支持有问题，建议shell shell： ansible all -m shell -a &apos;echo $HOSTNAME&apos; 更改口令: ansible all -m shell -a &apos;echo magedu|passwd --stdin test1&apos; script： chmod +x test.sh ansible all -m script -a ‘/root/ansible/test.sh’在所有主机上执行test.sh ansible all -a ‘getenforce’ cp /etc/sysconfig/selinux &gt;vim selinux copy:ansible-doc -s copy ansible all -m copy -a ‘src=/root/ansible/selinux dest=/etc/selinux/config backup=yes’文件复制 ansible all -m shell -a ‘getenforce’ ansible all -m copy -a ‘src=/etc/shadow dest=/data mode=000 owner=root’ ansible all -m copy -a ‘content=”hello\\n thanks \\n “ dest=/data/f2’直接写内容生成文件 fetch：从客户端去文件到服务器端，与copy相反 ansible all -m fetch -a ‘src=/var/log/messages dest=/data’从远程主机抓取log/message,到服务器，仅限单个文件 ansible all -m shell -a ‘tar jcf log.tar.xz /var/log/*.log’ 包的加压与解压archiveunarchive file： ansible all -m file -a ‘name=/data/f3 state=touch’ 创建文件 ansible all -m file -a ‘name=/data/f3 state=absent’ 删除文件 ansible all -a ‘ls -l /data’ ansible all -m file -a ‘name=/data/dir1 state=directory’ 创建文件夹，’state=absent’ 删除 ‘src=/etc/fstab dest=/data/fstab.link state=link’ 创建软连接 ‘dest=/data/fstab.link state=absent’ 删除软连接 ‘dest=/data/* state=absent’ 删除所有文件 ‘dest=/data/ state=absent’ 删除文件夹 不能删除挂载点上的 ansible 192.168.80.101 -m hostname -a ‘name=new_name’ 修改主机名 cron： ansible all -m cron -a ‘minute=* weekday=1,3,5 job=”/usr/bin/wall FBI warning” name=warningcron’ 创建定时报警任务，写入crontab ansible all -m cron -a ‘disabled=true job=”/usr/bin/wall FBI warning” name=warningcron’ 禁用此任务，必须加name ‘job=”/usr/bin/wall FBI warning” name=warningcron state=absent’ 删除 yum/etc/yum.repos/base.repo yum仓库配置 ansible all -m yum -a ‘name=vsftpd’安装多个软件用’,’隔开 ansible all -m yun -a ‘list=instealled’ 安装过的列表 ‘name=vsftpd state=removed’卸载 ‘name=vsftpd state=absent’ ‘rpm -q vsftpd’ 查找是否卸载 安装下载好的软件；ansible all -m copy -a ‘src=/data/softname dest=/root/‘ ansible all -a ‘ls /root/‘ ansbile all -m yum -a ‘name=/root/softname’ disable_gpg_check=yes 忽略，禁用 ‘name=dstat update_cache=yes’ 更新缓存 services: ansible all -m services -a ‘name=vsftpd state=started enabled=yes’启动服务，同时设为开机启动 user: ansible all -m user -a ‘name=nginx shell=/sbin/nologin system=yes home=/var/nginx groups=root,bin uid=80 comment=”nginx service”‘ 创建账号 ansible all -m user -a ‘name=nginx state=absent remove=yes’ 删除账号，删除home目录 group: ansible all -m group -a ‘name=nginx system=yes gid=80’ ansible all -a ‘getent group nginx’ ansible -m group -a ‘name=nginx state=absent’ 删除 ansible-galaxy: ansible-galaxy install geerlingguy.nginx yml/yaml: 注意缩进，格式 --- -hosts:webserver remote_user:root tasks: -name:hello command：hostname ansible-playbook test.yaml ansible-vault:ansible-vault encrypt test.yaml 对文件进行加密，避免敏感信息泄露 需要设置加密口令,再次执行yaml时会报错， ansible-vault decrypt test.yaml 解密 ansible-vault view test.yaml 查看yaml需要输入口令 ansible-vault rekey test.yaml 修改密码 ansible-vault create test2.yaml 创建新的playbook文件 ansible-console: 交互式：ansible-console “root@all (3)[f:5]$ “ 并发数量为5也可以修改forks 10 cd 192.168.80.135 切换到135主机 hostname name=node2.magedu.com 修改主机名 playbookplaybook采用YAMl语言编写 1.# test yaml 注释2.缩进必须统一 --- - hosts:webserver remote_user:root tasks: - name:create new file #描述 file:name=/data/newfile state=touch 模块/命令 - name:create new user user: name=test2 - name: install httpd yum:name=httpd - name:copy conf copy:src=/etc/conf dest=/etc/conf - name:start service service:name=httpd state=started enables=yes ansible-playbook -C file.yml # -C 检查 ansible all -a ‘getent passwd test2’ #查看test2用户 ansible all -m shell -a ‘ss -tln | grep :80’ #查看80端口 ansible all -a ‘getent passwd test2’ –limit 192.168.80.134 ansibel-playbook file.yml –list ansibel-playbook file.yml –list-tasks - name:copy a file copy:src=files/test.py dest=/etc/test.py #files相对路径，相对于当前目录 注：文件修改后再次执行copy，不会生效 更新配置文件，执行playbook后，并不会生效 http.yml --- - hosts: webserver remote_user:root tasks: - name:install https package yum:name-httpd - name: copy conf file copy: src=files/httpd.conf dest=/etc/httpd/conf baskup=yes - name: start service service: name=httpd state=started enabled=yes 执行http.yml，修改配置文件后，执行不会重启 http.yml --- - hosts: webserver remote_user:root tasks: - name:install https package yum:name-httpd tag:inshttpd - name: copy conf file copy: src=files/httpd.conf dest=/etc/httpd/conf baskup=yes notify:restart service - name: start service service: name=httpd state=started enabled=yes tag:rshttpd handlers: - name: restart service service: name=http state=restarted 也可以同时触发两个任务 tags： 添加标签，可以单独执行标签 多个动作共用一个标签 ansible-playbook -t rshttpd httpd.yml ansible-playbook -t inshttpd,rshttpd httpd.yml setup: ansible all -m setup -a ‘filter=ansible_hostname’ ansible all -m setup -a ‘filter=address‘\\ ansible all -m setup -a ‘filter=ansible_all_ipv4_address’ app.yml --- - hosts: webserver remote_user: root tasks: - name: install packing yum: name={{ pkname }} - name: start service service: name={{ pkname }} state=started enabled=yes ansible-playbook -e ‘pkname=httpd’ app.yml pkname 不会写死，灵活定义 也可以同时装多个包，用逗号隔开 eg： --- - hosts:websever remote_user: root vars: - pkname1: httpd - pkname2: vsftpd tasks: - name:install pachage yum: name={{ pkname1 }} - name: install package yum: name={{ pkname2 }} 定义变量在playbook中， hostname.yml: --- - hosts: webserver rempte_user: root tasks: - name: set hostname hostname: name= www{{http_port}}.magedu.com hosts： [webserver:vars] nodenamw=www domainname=magedu.com 此处的变量对webserver所有主机有效 tasks: - name: set hostname hostname：name={{nodename}}{{http_port}}.{{domasinname}} 命令行优先级高于配置文件 ansible all -m setupansible all -m setup -a ‘filter=”ansbile_fqdn”‘ var.yml --- - hosts:webserver renote_use: root tasks: - name: create a file file: name=/data/{{ ansible_fqdn }}.log state=touch mode=600 owner=wang ansible-playbook -c var.yml vars.yml var1: httpdvar2: vsftpd testvars.yml --- - hosts: webserver remote_user: root vars_file: - vars.yml tasks: - name：install package yum: name={{ var1 }} - name: create file file: name= /data/{{ var2 }}.log state=touch template.yml --- - hosts: webserver remote_user: root tasks: - name: install package tum: name=nginx - name: copy template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf - name start service service: name=nginx state=started enabled=yes ansible all -m shell -a ‘ss -ntpl’ #查看端口 nginx.conf中修改: worker_processes NaN #cpu个数的2次方 修改template.yml --- - hosts: webserver remote_user: root tasks: - name: install package tum: name=nginx - name: copy template template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf notify: start service - name start service service: name=nginx state=started enabled=yes handlers: - name: restart service service: name=nginx state=restarted ansible all -m shell -a ‘ps aux | grep nginx’ #过滤nginx进程 hosts：也可以写成如下模式 [webserver]192.168.80.134 http_port=81192.168.80.135 http_port=82 ansible-playbook -e ‘http_port=99’ testtemp.yml #修改端口 优先级：命令行&gt;playbook&gt;主机清单 ansibel all -m setup -a ‘filte=ansible_os_family’ ‘filter=”distribution“‘ testitem.yml --- - hosts: webserver remote_user: root tasks: - name: create some files file: name=/data/{{ item }} state=touch when: ansible_distribution_major_version == &quot;7&quot; with_items: - file1 - file2 - file3 - name: install spme package yum: name={{ item }} with_items: - htop - sl - hping3 create_group.yml --- - hosts: all remote_user: root tasks: - name: create some groups group: name={{ item }} when: ansible_distribution_major_version == &quot;7&quot; with_items: - g1 - g2 - g3 创建用户，并加入到组 --- - hosts: all remote_user: root tasks: - name: create some groups group: name={{ item }} when: ansible_distribution_major_version == &quot;7&quot; with_items: - g1 - g2 - g3 - name:create some users user: name={{item.name}} group={{item.group}} with_items: - { name: &apos;user1&apos;, group: &apos;g1&apos; } - { name: &apos;user2&apos;, group: &apos;g2&apos; } - { name: &apos;user3&apos;, group: &apos;g3&apos; } for: testfor.yml --- - hosts: all remote_user: root vars: ports: - 81 - 82 - 83 tasks: - name: copy conf template: src=for1.conf.j2 dest=/data/for1.conf 创建文件：for1.conf.j2 {% for port in ports %} server{ listen {{ port }} } {% endfor %} 修改为字典模式： --- - hosts: all remote_user: root vars: ports: - listen_port:81 - listen_port:82 - listen_port:83 tasks: - name: copy conf template: src=for2.conf.j2 dest=/data/for1.conf for2.conf.j2 {% for port in ports %} server{ listen {{ port.listen_port }} } {% endfor %} --- - hosts: all remote_user: root vars: ports: - web1: port: 81 name: web1.magedu.com rootdir: /data/website1 - web2: port: 83 name: web2.magedu.com rootdir: /data/website2 - web3: port: 83 name: web3.magedu.com rootdir: /data/website3 tasks: - name: copy conf template: src=for3.conf.j2 dest=/data/for1.conf for3.conf.j22 {% for p in ports %} server{ listen {{ p.port }} servername {{ p.name }} documentroot {{ p.rootdir }} } {% endfor %} --- - hosts: all remote_user: root vars: ports: - web1: port: 81 #name: web1.magedu.com rootdir: /data/website1 - web2: port: 83 name: web2.magedu.com rootdir: /data/website2 - web3: port: 83 #name: web3.magedu.com rootdir: /data/website3 tasks: - name: copy conf template: src=for4.conf.j2 dest=/data/for4.conf for4.conf.j22 {% for p in ports %} server{ listen {{ p.port }} {% if p.name is defined %} servername {{ p.name }} {% endif %} documentroot {{ p.rootdir }} } {% endfor %} roles创建roles文件夹： mkdir roles mkdir roles/{httpd, mysql, memcache} -pv mkdir roles/nginx ansible all -m shell -a ‘rpm -q nginx’ ‘getent group nginx’ ‘userdel -f nginx’ 删除用户，组 cd nginx mkdir tasks templates cd tasks vim group.yml - name:create group group: name=nginx gid=80 vim user.yml - name: create user user: name=nginx group=nginx system=yes shell=/sbin/nologin uid=80 vim yum.yml - name: install package yum: name=nginx vim start.yml - name: start service service: name=nginx state=started enabled=yes vim restart.yml - name: restart service sservice: name=nginx state=restarted templates: nginx.conf.j2(nginx.conf重命名为此) vim temp.yml - name: copy conf template: src=nginx.conf.j2 dest=/etc/ngiunx/nginx.conf vim main.yml - include: group.yml - include: user.yml - include: yum.yml - include: temp.yml - include: start.yml 调用的剧本与roles同级 vim nginx_role.yml - hosts: all remote_usr: root roles: - role: nginx ansibel-playbook -c nginx_role.yml httpd_roles mkdir tasks vim user.yml - name: create user user: name=apache system=yes shell=/sbin/nologin vim copyfile.yml - name: copy file file: src= dest= httpd： tasks： vim user.yml - name: create user user: name=apache system=yes shell=/sbin/nologin vim copyfile.yml - name: copy file copy: src=httpd.conf dest=/data/ vim main.yml - include: user.yml - include: copyfile.yml vim httpd_role.yml - hosts: all remote_user: root roles: - role: httpd 在一个角色中，调用另一个角色 vim some_role.yml - hosts: all remote_user：root roles: - role: http - role: nginx 一个角色引用另一个角色中的任务在main.yml中添加一行 - include: roles/httpd/tasks/copyfileyml 此处需要注意路径的选择 ansible.cfg 当playbook失败的情况下，一个重试文件将会创建，后缀为retry，默认开启此功能 添加标签：some_role.yml --- - hosts: all remote_user: root roles: - { role: httpd, tags:[&apos;web&apos;, &apos;httpd&apos;] } #即属于web，也属于httpd - { role: nginx, tags:[&apos;web&apos;, &apos;nginx&apos;] } ansible-playbook -t web some_role.yml #只执行标签web some_role.yml --- - hosts: all remote_user: root roles: - { role: httpd, tags:[&apos;web&apos;, &apos;httpd&apos;] } #即属于web，也属于httpd - { role: nginx, tags:[&apos;web&apos;, &apos;nginx&apos;] , when: ansible_distribution_major_version == &apos;7&apos;} # 当版本为7的时候执行 mkdir appcd appmkdir tasks templates vars handlers files task: vim group.yml - name: create group group: name=app system=yes gid=123 vim user.yml - name: create user user: name=app group=app system=yes shell=/sbin/nologin uid=1223 vim yum.yml - name: isntall package yum: name=httpd vim templ.yml - name: copy conf template: src=httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf notify: restart service vars:main.yml username:app groupname: app handlers:vim main.yml - name: restart service service: name=httpd state=restarted tasks: vim start.yml - name: start service service: name=httpd state=started enabled=yes vim copyfile.yml - name: copy config copy: src=vhosts.conf dest=/etc/httpd/conf.d/ owner=app vim main.yml - include: group.yml - include: user.yml - include: yum.yml - include: templ.yml - include: copyfile.yml - include: start.yml files:touch vhosts.conf app_role.yml - hosts: all remote_user: root roles: - app memcached: yum install memcached cat /etc/sysconfig/memcached cp /etc/sysconfig/memcached templates/memcached.j2修改：CACHESIZE=”NaN“ vim tasks/yum.yml - name: install package yum: name=memcached vim taska/start.yml - name: start service service: name=memcached state=started enabled=yes vim /tasks/templ.yml - name: copy conf templates: src=memcached.j2 dest=/etc/sysconfig/memcached vim tasks/main.yml - include: yum.yml - include: templ.yml - include: start.yml vim memcached_role.yml - hosts: all remote_user: root roles: - memcached ansible-playbook -C memecached_role.yml ansible-playbook memcached_role.yml","categories":[{"name":"ansible","slug":"ansible","permalink":"http://www.baidu.com/categories/ansible/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://www.baidu.com/tags/ansible/"}],"author":"yuanfeng"}]}